{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72783e71-969b-4dbd-85a0-d6feb3b8d118",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Statistics in Python: *t* tests and *z* scores with SciPy\n",
    "---\n",
    "\n",
    "## Learning Objetives\n",
    "- implement paired and unpaired *t* tests using the SciPy package\n",
    "- implement paired and unpaired *z* test using the SciPy package\n",
    "- implement ANOVA and repeated measures ANOVA using the statsmodels package\n",
    "- implement general linear mixed effects analysis using the statsmodels package\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "An introductory course in statistics is a prerequisite for this class, so we assume you remember (some of) the basics including *t*-tests, *z*-tests, ANOVAs, and regression (or at least correlation). \n",
    "\n",
    "Here we will demonstrate how to perform these statistical tests in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e8d2f-8de3-43f7-9e22-4b3929d9d107",
   "metadata": {},
   "source": [
    "## *t* Test\n",
    "\n",
    "A *t* test is used to compare the means of two sets of data. For example, in the flanker experiment we used in the [previous section](./repeated_meaasures), we could compare the mean RTs for the congruent and incongruent conditions. *t* tests consider the size of the difference between the means of the two data sets, relative to the variance in each one. The less the distributions of values in the two data sets overlap, the larger the *t* value will tend to be. We can then estimate the probability that the observed difference occurred simply by chance, rather than due to a true difference — this is the *p* value. Typically, researchers use a *p* < .05 threshold to determine statistical significance. \n",
    "\n",
    "*t* tests are implemented in the [SciPy](https://docs.scipy.org) library, which \"provides many user-friendly and efficient numerical routines, such as routines for numerical integration, interpolation, optimization, linear algebra, and statistics.\" Each of those type of routines is in a separate sub-module of SciPy; the one we'll want is `scipy.stats`. We can import this specific module with the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0240588e-b6d6-43db-b65d-6a6e6b28e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4fe04-9ef7-4090-b434-1a869de22dce",
   "metadata": {},
   "source": [
    "We'll also import some other packages we'll need, and the flanker data from the previous lesson to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663b7b91-8352-40ea-be68-31ed1df7c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv('data/flanker_rt_data.csv')\n",
    "\n",
    "## Aggregate the data across participants\n",
    "df_avg = pd.DataFrame(df.groupby(['participant', 'flankers'])['rt'].mean()).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fbe3c-3026-46ed-b08b-80cb38995030",
   "metadata": {},
   "source": [
    "## Paired *t*-test\n",
    "\n",
    "Let's start by comparing the mean RTs for the congruent and incongruent flanker conditions. \n",
    "\n",
    "Recall that we are working with repeated-measures data – for each participant, we have 160 trials across 4 conditions. *t* tests are not meant for *within-condition* repeated measures data — we need only one measurement per participant in each condition. This is for essentially the same reason discussed at the end of the previous section on repeated measures data: if we treat the within-participant variability the same as the between-participant variability, then we will tend to grossly under-estimate the true (between-participant) variance. When running a *t* test, this would result in erroneously large *t* values that could often falsely suggest a statistically significant result. So, we need to use the aggregated data, `df_avg`. \n",
    "\n",
    "The other important characteristic of our data are that, even though aggregation has reduced the data to one measurement per participant, we still have repeated measures, across the two conditions. The default assumption of a *t* test is that each of the two data sets being compared come from different samples of the population (often called a *between-subjects design* in Psychology). This means that *t* tests assume there is no relationship between any particular measurement in each of the two data sets being compared. When we have measurements from the same people in both data sets (a *within-subjects. design*), we need to account for this, or the *t* test will again suggest an inflated (incorrect) value. We account for this by using a **paired *t* test**. In SciPy, this is the function [`ttest_rel()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html).  (For a between-subjects — or *independent groups* design, which we will not cover here, you would use [`ttest_ind()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)).\n",
    "\n",
    "Running `ttest_rel()` is as simple as giving it the two sets of data you want to compare, as arguments. We can pull these directly from our `df_avg` pandas DataFrame. We'll do this in a few lines of code below, first assigning each data set to a new variable, and then running the *t* test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d3ade0-85ea-4140-99e7-c757ac97eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "congr = df_avg[df_avg['flankers'] == 'congruent']['rt']\n",
    "incongr = df_avg[df_avg['flankers'] == 'incongruent']['rt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8757e-0f48-4db9-8967-e4632bc2fbf2",
   "metadata": {},
   "source": [
    "Let's make sure you understand the code above before we go on. We've seen it before, but maybe not in exactly this form — and it is quite complex, but logical.\n",
    "\n",
    "We start on the first line by selecting only the rows of the DataFrame associated with congruent trials, which returns a Boolean mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35950f4e-cdf8-4a22-b203-4f8ba0986ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2     False\n",
       "3      True\n",
       "4     False\n",
       "      ...  \n",
       "76    False\n",
       "77    False\n",
       "78     True\n",
       "79    False\n",
       "80    False\n",
       "Name: flankers, Length: 81, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg['flankers'] == 'congruent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ab3e5-b57a-4ab9-b209-70fcef1ba67c",
   "metadata": {},
   "source": [
    "We embed this inside another selector `df_avg[df_avg['flankers'] == 'congruent']`, which applies the Boolean mask to the DataFrame, essentially saying, \"select from `df_avg` all the columns associated with congruent trials\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09892e53-7faf-4e30-810b-5830b27abbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>flankers</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.455259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s10</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.471231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s11</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.417540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s12</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.429758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s13</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.419096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s14</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.437178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s15</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.548638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s16</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.433748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s17</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.437577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>s18</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.488892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>s19</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.539020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>s2</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.438167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>s20</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.462935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>s21</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.417553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>s22</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.410191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>s23</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.549622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>s24</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.568396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>s25</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.450102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>s26</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.528508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>s27</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.439243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>s3</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.570766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>s4</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.401993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>s5</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.462927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>s6</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.446840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>s7</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.628185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>s8</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.428642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>s9</td>\n",
       "      <td>congruent</td>\n",
       "      <td>0.431829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant   flankers        rt\n",
       "0           s1  congruent  0.455259\n",
       "3          s10  congruent  0.471231\n",
       "6          s11  congruent  0.417540\n",
       "9          s12  congruent  0.429758\n",
       "12         s13  congruent  0.419096\n",
       "15         s14  congruent  0.437178\n",
       "18         s15  congruent  0.548638\n",
       "21         s16  congruent  0.433748\n",
       "24         s17  congruent  0.437577\n",
       "27         s18  congruent  0.488892\n",
       "30         s19  congruent  0.539020\n",
       "33          s2  congruent  0.438167\n",
       "36         s20  congruent  0.462935\n",
       "39         s21  congruent  0.417553\n",
       "42         s22  congruent  0.410191\n",
       "45         s23  congruent  0.549622\n",
       "48         s24  congruent  0.568396\n",
       "51         s25  congruent  0.450102\n",
       "54         s26  congruent  0.528508\n",
       "57         s27  congruent  0.439243\n",
       "60          s3  congruent  0.570766\n",
       "63          s4  congruent  0.401993\n",
       "66          s5  congruent  0.462927\n",
       "69          s6  congruent  0.446840\n",
       "72          s7  congruent  0.628185\n",
       "75          s8  congruent  0.428642\n",
       "78          s9  congruent  0.431829"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg[df_avg['flankers'] == 'congruent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76921e9-781c-4e51-9bad-b5704a1f1859",
   "metadata": {},
   "source": [
    "Finally, we add ['rt'] to the end to indicate that, having selected the incongruent rows, we actually only want the column with the RT values, because those are what we want to perform the *t* test on. The second line does the same thing for incongruent trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0e02a6-20ba-4b8e-9fed-5c2723e2218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.455259\n",
       "3     0.471231\n",
       "6     0.417540\n",
       "9     0.429758\n",
       "12    0.419096\n",
       "15    0.437178\n",
       "18    0.548638\n",
       "21    0.433748\n",
       "24    0.437577\n",
       "27    0.488892\n",
       "30    0.539020\n",
       "33    0.438167\n",
       "36    0.462935\n",
       "39    0.417553\n",
       "42    0.410191\n",
       "45    0.549622\n",
       "48    0.568396\n",
       "51    0.450102\n",
       "54    0.528508\n",
       "57    0.439243\n",
       "60    0.570766\n",
       "63    0.401993\n",
       "66    0.462927\n",
       "69    0.446840\n",
       "72    0.628185\n",
       "75    0.428642\n",
       "78    0.431829\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg[df_avg['flankers'] == 'congruent']['rt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e34ad-1b35-4673-9c88-30f6ed9e5272",
   "metadata": {},
   "source": [
    "This last result is what we assign to `congr` (note, by the way, that this is a pandas Series, not a DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4849d52a-0176-45a5-b01e-a569b484127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.455259\n",
       "3     0.471231\n",
       "6     0.417540\n",
       "9     0.429758\n",
       "12    0.419096\n",
       "15    0.437178\n",
       "18    0.548638\n",
       "21    0.433748\n",
       "24    0.437577\n",
       "27    0.488892\n",
       "30    0.539020\n",
       "33    0.438167\n",
       "36    0.462935\n",
       "39    0.417553\n",
       "42    0.410191\n",
       "45    0.549622\n",
       "48    0.568396\n",
       "51    0.450102\n",
       "54    0.528508\n",
       "57    0.439243\n",
       "60    0.570766\n",
       "63    0.401993\n",
       "66    0.462927\n",
       "69    0.446840\n",
       "72    0.628185\n",
       "75    0.428642\n",
       "78    0.431829\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0528db6-38bb-4ad6-9a6b-8f7f6dcd3961",
   "metadata": {},
   "source": [
    "Likewise, `incongr` is a Series of the same length (the number of participants):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b3769a-ce69-4120-8c89-818017c8c442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.471838\n",
       "4     0.499031\n",
       "7     0.473012\n",
       "10    0.506722\n",
       "13    0.478367\n",
       "16    0.453524\n",
       "19    0.591644\n",
       "22    0.492921\n",
       "25    0.504452\n",
       "28    0.527152\n",
       "31    0.591181\n",
       "34    0.518216\n",
       "37    0.507257\n",
       "40    0.507033\n",
       "43    0.474612\n",
       "46    0.554172\n",
       "49    0.595977\n",
       "52    0.513179\n",
       "55    0.565531\n",
       "58    0.501069\n",
       "61    0.591022\n",
       "64    0.428867\n",
       "67    0.530722\n",
       "70    0.490298\n",
       "73    0.650769\n",
       "76    0.494878\n",
       "79    0.437926\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incongr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace238b-901e-4ee6-84ba-689635b694fd",
   "metadata": {},
   "source": [
    "Now we just pass `congr` and `incongr` as the first (and only) two arguments to `ttest_rel()`, and print the results out with some explanatory text. Note that we have to write `stats.ttest_rel()`, because we imported the library as `stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ea1df7-ce07-4e44-bf97-da4eb21138f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -10.209634805365013  p =  1.3739296579820675e-10\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_rel(congr, incongr)\n",
    "print('Congruent vs. Incongruent t = ', str(t), ' p = ', str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315368ad-d006-4f12-acdd-c97fd3434c33",
   "metadata": {},
   "source": [
    "We can make the output nicer by rounding to a reasonable level of precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b721e4-d89e-4225-b0d1-d5ff8aa29754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -10.21  p =  0.0\n"
     ]
    }
   ],
   "source": [
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab284c88-df8e-4b2e-bc1f-ec7fb8cc130c",
   "metadata": {},
   "source": [
    "Now that's a results any researcher would be happy to see! The *p* value is not actually zero by the way, but note in the original output the *p* value was reported in scientific notation, ending in `e-10`. This means that the *p* value is actually 0.00000000013739. We would typically report this as *p* < .0001, since we rounded to 4 decimal places (which is fairly typical for reporting *p* values).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0cd19-06ee-45f0-9ecd-ce031045d9ee",
   "metadata": {},
   "source": [
    "## Be careful about order of data values\n",
    "\n",
    "The above paired *t* test worked properly because in our pandas DataFrame, participants are listed in a consistent order. So when we create separate Series for congruent and incongruent, the same rows of the two Series belong to the same participant. However, this isn't always guaranteed, and so it's good practice to do things in a way that ensures proper pairing of participants between data sets. \n",
    "\n",
    "pandas indexing allows us to do this. Recall that indexes are row labels. By default, when we read a CSV file to a DataFrame, the rows are indexed numerically starting from zero. Indeed, if you look back above at the contents of `congr` and `incongr`, you'll see the indexes in the left column are discontinuous and different between the two, because each data point came from a separate row. To ensure alignment of each participant's data across the two series, we can first use the participant ID as the index of `df_avg`, and then create separate Series for each condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27db15d-741f-4f0e-84ec-4dd66e95f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df_avg.set_index('participant')\n",
    "congr = df_avg[df_avg['flankers'] == 'congruent']['rt']\n",
    "incongr = df_avg[df_avg['flankers'] == 'incongruent']['rt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9ddfb-f4f1-4821-83ca-bba8ed66df65",
   "metadata": {},
   "source": [
    "Now when we look at the resulting Series, we see that the participant indexes are preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f57277-2c1f-42eb-83cb-2af5069b22b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant\n",
       "s1     0.455259\n",
       "s10    0.471231\n",
       "s11    0.417540\n",
       "s12    0.429758\n",
       "s13    0.419096\n",
       "s14    0.437178\n",
       "s15    0.548638\n",
       "s16    0.433748\n",
       "s17    0.437577\n",
       "s18    0.488892\n",
       "s19    0.539020\n",
       "s2     0.438167\n",
       "s20    0.462935\n",
       "s21    0.417553\n",
       "s22    0.410191\n",
       "s23    0.549622\n",
       "s24    0.568396\n",
       "s25    0.450102\n",
       "s26    0.528508\n",
       "s27    0.439243\n",
       "s3     0.570766\n",
       "s4     0.401993\n",
       "s5     0.462927\n",
       "s6     0.446840\n",
       "s7     0.628185\n",
       "s8     0.428642\n",
       "s9     0.431829\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3a6989-6a56-4920-b01f-88cc049104fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant\n",
       "s1     0.471838\n",
       "s10    0.499031\n",
       "s11    0.473012\n",
       "s12    0.506722\n",
       "s13    0.478367\n",
       "s14    0.453524\n",
       "s15    0.591644\n",
       "s16    0.492921\n",
       "s17    0.504452\n",
       "s18    0.527152\n",
       "s19    0.591181\n",
       "s2     0.518216\n",
       "s20    0.507257\n",
       "s21    0.507033\n",
       "s22    0.474612\n",
       "s23    0.554172\n",
       "s24    0.595977\n",
       "s25    0.513179\n",
       "s26    0.565531\n",
       "s27    0.501069\n",
       "s3     0.591022\n",
       "s4     0.428867\n",
       "s5     0.530722\n",
       "s6     0.490298\n",
       "s7     0.650769\n",
       "s8     0.494878\n",
       "s9     0.437926\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incongr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283839b-9ae3-43e0-9421-5c8c6a3b50ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Randomize associations between ID and RT\n",
    "\n",
    "To make the point that the order of the data values in each of the two data sets being compared is important, let's randomize the order of the data values in the incongruent data. We'll save this as a new variable/Series, `incongr2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe537f28-cd05-4bc4-8a86-3f5acf4065ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/pvpjfdzd39sc5rqvsk5lvv4m0000gn/T/ipykernel_23291/2459672336.py:2: UserWarning: you are shuffling a 'Series' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(incongr2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "participant\n",
       "s1     0.595977\n",
       "s10    0.507257\n",
       "s11    0.650769\n",
       "s12    0.428867\n",
       "s13    0.591022\n",
       "s14    0.453524\n",
       "s15    0.518216\n",
       "s16    0.504452\n",
       "s17    0.527152\n",
       "s18    0.501069\n",
       "s19    0.506722\n",
       "s2     0.474612\n",
       "s20    0.591181\n",
       "s21    0.507033\n",
       "s22    0.494878\n",
       "s23    0.490298\n",
       "s24    0.499031\n",
       "s25    0.492921\n",
       "s26    0.565531\n",
       "s27    0.437926\n",
       "s3     0.591644\n",
       "s4     0.554172\n",
       "s5     0.530722\n",
       "s6     0.473012\n",
       "s7     0.513179\n",
       "s8     0.471838\n",
       "s9     0.478367\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incongr2 = incongr.copy()\n",
    "np.random.shuffle(incongr2)\n",
    "incongr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1d096-197f-488d-a119-20c3de6fddcc",
   "metadata": {},
   "source": [
    "Now when we run the *t* test, we see when get different *t* and *p* values. In fact, if you run the cell above and then the cell below repeatedly, you'll get a different *t* value each time, because the pairing between congruent and incongruent RTs will be randomly different each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "628c2fa2-653b-490a-a5a2-99e340e862f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -2.71  p =  0.0119\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_rel(congr, incongr2)\n",
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f1570-521c-4264-aa5c-ed381261b81d",
   "metadata": {},
   "source": [
    "In many cases this error can easily be avoided by ensuring that your data are listed in the same order in both data sets you're comparing. But if your data aren't (or you aren't sure), how do you ensure that the order is matched? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dd5c8-18b2-430a-b9d1-7accaada126b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Randomize order of incongruent data, but preserve association netween ID and RT\n",
    "\n",
    "It turns out that SciPy's `ttest` functions ignore pandas indexes, so indexing on its own won't ensure that the *t* test compares data points from the same individuals. We can see that by randomizing the order of the rows of the `incongr2` series, while preserving the relationship between participant IDs and RTs (you can compare with above data to confirm that the same RT values are associated with the same IDs as in the original `incongr` Series): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d0d99f-d18e-495e-8336-6c7ba5935abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant\n",
       "s25    0.513179\n",
       "s10    0.499031\n",
       "s24    0.595977\n",
       "s8     0.494878\n",
       "s7     0.650769\n",
       "s19    0.591181\n",
       "s12    0.506722\n",
       "s5     0.530722\n",
       "s14    0.453524\n",
       "s22    0.474612\n",
       "s9     0.437926\n",
       "s3     0.591022\n",
       "s11    0.473012\n",
       "s6     0.490298\n",
       "s21    0.507033\n",
       "s23    0.554172\n",
       "s2     0.518216\n",
       "s20    0.507257\n",
       "s26    0.565531\n",
       "s18    0.527152\n",
       "s27    0.501069\n",
       "s16    0.492921\n",
       "s17    0.504452\n",
       "s4     0.428867\n",
       "s13    0.478367\n",
       "s15    0.591644\n",
       "s1     0.471838\n",
       "Name: rt, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg = df_avg.reset_index()\n",
    "inc_arr = np.array(df_avg[df_avg['flankers']=='incongruent'].iloc[:, [0, 2]])\n",
    "np.random.shuffle(inc_arr)\n",
    "incongr2 = pd.DataFrame(inc_arr, columns=['participant', 'rt']).set_index('participant')\n",
    "incongr2 = pd.Series(incongr2['rt'])\n",
    "incongr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283260c-6814-4a84-a0bc-0ff2c3e57c19",
   "metadata": {},
   "source": [
    "But when we run the *t* test, the *t* value doesn't match the value of 10.21 that we got with the properly-paired data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd5816e2-19e0-4ffc-b124-8b3baadde051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -2.71  p =  0.0119\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_rel(congr, incongr2)\n",
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267af3f-c61b-4ccc-b9b7-b559f42a501c",
   "metadata": {},
   "source": [
    "The way we can fix this is by *re-ordering* the data in both Series that we're comparing (`congr` and `incongr2` in this case), using pandas `.sort_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aaf4db0-3133-4259-b55d-b73fce10d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -10.21  p =  0.0\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_rel(congr.sort_index(), incongr2.sort_index())\n",
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72202d04-dd4e-4673-ad4a-c235bd85690c",
   "metadata": {},
   "source": [
    "Long story short, it is good practice to index by participant ID, and use the `.sort_index()` method when applying *t* tests to pandas Series or DataFrames, to ensure that values are appropriately paired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7b39e-f926-4b82-b466-ba0bb3a85f44",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing differences: one-sample *t* tests\n",
    "\n",
    "An alternative way to compare the congruent and incongruent conditions is to compute the difference in mean RTs between the two conditions for each participant (since it is a paired design), and then run a *t* test on the differences. In this case, we use a **one sample** *t* test, in which we compare the data set to zero. In other words, is the difference between the conditions basically zero, or is it significantly different from zero (i.e., a believable difference)?\n",
    "\n",
    "We can compute the difference between two pandas Series easily just using the `-` (minus) operator, so in this case we could use:\n",
    "\n",
    "~~~python\n",
    "congr - incongr\n",
    "~~~\n",
    "\n",
    "Note that this subtraction *only* works if the two Series are indexed by participant ID (or in some way that preserves the alignment of values between the two data sets). However, because we are subtracting two pandas objects, pandas recognizes the indexes in each and aligns them, even if the indexes aren't in the same order in the two input Series. \n",
    "\n",
    "In other words, we get the same result from the 1 sample *t* test if we perform the subtraction on the two Series that have the same order of indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f368065-f93e-4b74-8644-d0749810c983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -10.21  p =  0.0\n"
     ]
    }
   ],
   "source": [
    "congr_vs_incongr = congr - incongr\n",
    "t, p = stats.ttest_1samp(congr_vs_incongr, 0)\n",
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730d0f9-57b8-4f16-8ec1-b74b6a5fa552",
   "metadata": {},
   "source": [
    "...as when we perform the subtraction using `incongr2`, which has a randomly shuffled order of indexes. We don't need to explicitly `.sort_index()` in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9592edc-c3ac-4c98-b5fa-ddeb933da86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent vs. Incongruent t =  -10.21  p =  0.0\n"
     ]
    }
   ],
   "source": [
    "congr_vs_incongr = congr - incongr2\n",
    "t, p = stats.ttest_1samp(congr_vs_incongr, 0)\n",
    "print('Congruent vs. Incongruent t = ', str(round(t, 2)), ' p = ', str(round(p, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a4e45-30dc-4a28-b1d9-266cc8a6f14c",
   "metadata": {},
   "source": [
    "### Paired vs. 1-sample *t* tests\n",
    "\n",
    "You'll note the result of the 1-sample *t* test is the same as the paired *t* test above. This is expected, because in both cases we ran a *t* test to compare the difference between the same two sets of data. From a coding perspective, the paired *t* test is a bit simpler, because you don't have to perform a subtraction on the data prior to running the *t* test. The reasons we might want to run a 1-sample *t* test include cases where are data are already represented as a subtraction, or in some cases when we're working with multiple variables, performing subtractions can be a way of simplifying our presentation of the results. We will see examples of this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cde26-656c-48c2-9ecd-2f2cad3d2064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
