{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Multiple Data Files Using Copilot\n",
    "\n",
    "In this lesson we will revisit some of the material covered at the end of the introductory chapter on Python. Specifically, reading multiple data files, manipulating the data using pandas, and deriving some basic information from the data.\n",
    "\n",
    "The instructions are very high-level, because we want you to work on writing Copilot prompts yourself, based on high-level instructions rather than us giving you step-by step guidance. The version of this lesson in the online textbook, however, shows the worked example with prompts and Copilot-generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Your task is to perform the operations below, using Python code generated by a combination of your own writing, and GitHub Copilot's suggestions. For your own learning, you are best off to start each step by trying to write the code yourself. If it works, great – you've learned something in Python! Congratulations. But, tTe tasks below intentionally ask you to do things that we haven't taught in this course yet. That's because we want you to learn how to use Copilot to help you out when you don't know how to do something.\n",
    "\n",
    "If you try writing your own code and it doesn't work, then you can try again, or use Copilot to help you out. Copilot is meant to speed up your coding, so in practice it's preferable to use it to help you out when you get stuck, than spend too much time trying to figure out how to do something yourself. On the other hand, once you have the solution from Copilot, it's important to try to understand what it is doing. You may have to look up some of the functions it's using, if you're not familiar with them. \n",
    "\n",
    "If you're ignorant of what the code you generated is doing, you risk errors. Indeed, in the tutorial below we will see an example of Copilot's generating erroneous code. Even if the code works as desired, it is important for you to be able to explain correctly what you did. Also, look for ways to check that the results you get are correct (using code). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Data and What to Do With It\n",
    "\n",
    "There are three data files in the `data` directory: `s1.csv`, `s2.csv`, and `s3.csv`. Each file contains the reaction times (RTs) from 10 trials of a relatively simple task in which participants had to indicate which direction a briefly-presented arrow was pointing. The RTs are in seconds (s). Each file contains the RTs from a different participant. In each file there are three columns. You can determine what the columns are by looking at the first row (header) of each file.\n",
    "\n",
    "Generate code that reads in the three files and combines them in a pandas DataFrame. Include error-checking  code that determines you loaded in the correct number of trials (30) and the correct number of columns (3). If the number of trials or columns is incorrect, print an error message.\n",
    "\n",
    "Save the dataframe to a file called `all_data.csv`, in the `data` folder.\n",
    "\n",
    "Once you have the DataFrame, calculate:\n",
    "- the mean RT for each participant\n",
    "- the mean RT across all participants\n",
    "- the 95% confidence intervals for the mean RT for each participant\n",
    "- the 95% confidence intervals for the mean RT across all participants\n",
    "\n",
    "Print all of the above results to the screen, rounded to 2 decimal places and with accompanying text that indicates what each result is. Be sure that it is clear that RT is in seconds.\n",
    "\n",
    "As well, generate a plot of the mean RT for each participant, with error bars showing the 95% confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Approach This Exercise\n",
    "\n",
    "A critical skill to develop in coding is **problem decomposition** – in other words, breaking down a task into smaller and smaller components, so that you can write the code to perform each step in the logical sequence. The instructions above are written in a sequential way, so you should be able to identify each individual step that  you need to take.\n",
    "\n",
    "It is good practice, when working in Jupyter notebooks, to write the code for each step in a separate cell. This makes it easier to test each step, and to go back and change things if you need to. It also makes it easier to see what you've done, and understand what the code is doing. As well, it's sometime helpful to put Markdown cells in between code cells, to provide longer explanations than might be appropriate for a comment in the code itself. You can also make notes about things you might want to change later, or interpretations of the output of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Copilot Assistant\n",
    "\n",
    "As noted above, we encourage you to try writing the code for each step of the instructions above. Coding is a *procedural* skill that you only learn by doing — and the more you learn the better you will be at solving the bugs that Copilot-generated code will inevitably have. But, if you get stuck, or encounter an instruction that you haven't yet learned how to perform in Python, then by all means use Copilot. Just like writing your own code, it is best if you use a separate notebook cell for each Copilot prompt. That way, if you need to edit the code, you can do so without having to re-run all of the code that Copilot generated. It's also easier to debug because you can see the output of each cell and now exactly which line generated the error.\n",
    "\n",
    "As you will see, it takes some trial and error – and critical thinking – to generate prompts that produce the code you want. But, it's a good way to learn how to use Copilot effectively. And if you do it right, you will learn a lot about Python along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Copilot does not generate the same code every time you type the same prompt. This is the nature of the type of generative AI that Copilot uses. So, when working through this lesson, you may get different outputs than what is shown in the lesson. Try to use the processes explained here for interpreting error messages and Copilot's descriptions and suggested code. It's much more important to get familiar with engaging in the *process* of debugging, through the thought processes explained here, than to worry about getting different suggestions from Copilot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using Copilot to Perform the Tasks Above\n",
    "\n",
    "The cells below all reflect prompts written on the basis of the instructions above, and code generated entirely by Copilot. While your experience may be different, in writing this lesson we only had to type the first 2-line prompt, and Copilot generated not only the code but the other prompts/comments. \n",
    "\n",
    "However, you have to get used to the flow of working with Copilot. After typing the first two-line prompt below, if you only hit `Enter` once, you probably won't get any code generated. Copilot encourages a good coding style, and so it will only generate code if you hit `Enter` twice, so that there's an empty line between your prompt and the code. And in fact, after I typed the first two lines of the prompt and hit `Enter`, Copilot added a third suggested line to the prompt after I hit `Enter` the first time, which was to `write the dataframe to a csv file`. This is pretty cool, since that was also part of the instructions above! Is Copilot a mind-reader? No, it's just a very good predictor of what you might want to do next, based on the prompt you've written. It's a pretty common task in data science to read in a set of individual data files, concatenate them into a single DataFrame, and then save that DataFrame to a file for later use. So, Copilot is just doing what it's trained to do, which is to predict what you might want to do next, based on the prompt you've written.\n",
    "\n",
    "Anyway, after I accepted the third line of the prompt below, I had to hit `Enter` twice to get the first line of code (`import pandas as pd`) generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/s2.csv', 'data/s3.csv', 'data/s1.csv']\n"
     ]
    }
   ],
   "source": [
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# use glob to get all the files that start with \"s\" and end with \"csv\"\n",
    "# glob returns a list of file names\n",
    "filenames = glob.glob(\"data/s*.csv\")\n",
    "print(filenames)\n",
    "\n",
    "# read in the files and concatenate them into one dataframe\n",
    "dataframes = []\n",
    "for f in filenames:\n",
    "    dataframes.append(pd.read_csv(f))\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df\n",
    "\n",
    "# write the dataframe to a csv file\n",
    "df.to_csv(\"data/concatenated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above appears to have worked fine. Next we'll to some checks to confirm that, as described in the instructions. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Learning Point</b><p>\n",
    "The above appears to have worked fine. However, the above code uses a <code>for</code> loop to iterate over the files and read them in. There is a way we could do this in one line of code, using <em>list comprehension</em>:</p>\n",
    "\n",
    "```python\n",
    "df = pd.concat([pd.read_csv(f) for f in files])\n",
    "```\n",
    "\n",
    "This demonstrates that Copilot can generate working code, but not always the most efficient code.\n",
    "</div>\n",
    "\n",
    "For the moment, we'll stick with the code Copilot generated, and check that it is accurate. We'll start by checking the number of columns in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831\n",
       "3            s2      4  0.417988\n",
       "4            s2      5  0.371810"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the DataFrame has 3 columns, as expected. Next, we'll check that we get the expected number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the dataframe has 30 rows and 3 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also were instructed to raise an error message if the number of rows or columns is incorrect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise an error if the dataframe does not have 30 rows and 3 columns\n",
    "assert df.shape == (30, 3), \"The dataframe does not have 30 rows and 3 columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Test\n",
    "This generates no output. This is a Good Thing, because it means that the number of rows and columns is correct. However, it's a bit dangerous to assume no news is good news, because no news could also mean your code is not working. So, we should test that the error message is generated if we change the expected number of rows or columns.\n",
    "\n",
    "We don't want to actually remove any rows from the DataFrame, but we can use slicing to create a view of the DataFrame that has fewer rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The dataframe does not have 30 rows and 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y164sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create a slice of df that contains 29 rows, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y164sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# then raise an error if the dataframe does not have 30 rows and 3 columns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y164sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_slice \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:\u001b[39m29\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y164sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39massert\u001b[39;00m df_slice\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m30\u001b[39m, \u001b[39m3\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mThe dataframe does not have 30 rows and 3 columns\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dataframe does not have 30 rows and 3 columns"
     ]
    }
   ],
   "source": [
    "# create a slice of df that contains 29 rows, \n",
    "# then raise an error if the dataframe does not have 30 rows and 3 columns\n",
    "df_slice = df.iloc[0:29]\n",
    "assert df_slice.shape == (30, 3), \"The dataframe does not have 30 rows and 3 columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an `AssertionError`, which is a Good Thing because it confirms that our error-checking code is working. We can do the same thing to test the error-checking code for the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The dataframe does not have 30 rows and 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y200sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create a slice of df that contains 2 columns, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y200sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# then raise an error if the dataframe does not have 30 rows and 3 columns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y200sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_slice \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y200sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39massert\u001b[39;00m df_slice\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m30\u001b[39m, \u001b[39m3\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mThe dataframe does not have 30 rows and 3 columns\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dataframe does not have 30 rows and 3 columns"
     ]
    }
   ],
   "source": [
    "# create a slice of df that contains 2 columns, \n",
    "# then raise an error if the dataframe does not have 30 rows and 3 columns\n",
    "df_slice = df.iloc[:, 0:2]\n",
    "assert df_slice.shape == (30, 3), \"The dataframe does not have 30 rows and 3 columns\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, our code will throw errors if the number of rows or columns is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Mean RT for Each Participant... and Our First Bug\n",
    "Our next instruction is to calculate the mean RT for each participant. Let's prompt Copilot to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# calculate mean rt for each subject\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "# calculate mean rt for each subject\n",
    "df.groupby('subject').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Debugging Copilot-Generated Code\n",
    "\n",
    "Typically, when you get a long, scary error message like the one above, you can ignore a lof of what is in the middle. The most important parts are the last line, which tells you what the error is, and the first lines, which usually indicate what line in the code you tried to run caused the error. What's in between is the *stack trace*, which is a list of all the functions that were called in the process of trying to run the code. But most of the time, the error is a result of the code you wrote (the first lines), not the code in the underlying Python functions that your code called (the middle lines).\n",
    "\n",
    "In this case, we see a `KeyError: 'subject'` at the bottom of the error message. Recall that Python dictionaries are sets of **key**-value pairs. The keys are the names of the columns, and the values are the data in those columns. \n",
    "\n",
    "You can think of a pandas DataFrame as a dictionary in which the column names are keys, and the values in that column are its values. This is a common way that pandas functions refer to column names and their values. So the error message above indicates that the code tried to access a column called `subject` in the DataFrame, but that column doesn't exist. We can see at the top of the error message that the code that caused the error is: `---> 2 df.groupby('subject').mean()`. This means it's line 2 of the cell above that caused the error. \n",
    "\n",
    "As a novice coder, however, you might not know or remember that pandas DataFrames represent column names and data as dictionary key-value pairs. If you don't understand what an error means, you can use Copilot to help you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Copilot to Explain Errors and Suggest Fixes\n",
    "\n",
    "Somewhat counterintuitively, even though Copilot can generate code with bugs, it can also provide feedback on errors in the code it generated. \n",
    "\n",
    "Copilot has a few features that can help you diagnose and fix your code. If you right-click in a code cell, you will see `Copilot` within the menu that pops up. Under that heading there are a number of options, including `Explain This` and `Fix This`. Some work better than others, but we will look at each of them in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Copilot `Explain This`\n",
    "\n",
    "A great place to start in diagnosing errors is `Explain This`. Intuitively, you might go straight for `Fix This`. However, it's probably instructive to see what Copilot thinks your code is doing, and if that is what *you* think your code is doing. Copilot's explanation might give you insight into the error. Below is the output from selecting `Explain This` for the line of code that caused the error above:\n",
    "\n",
    "> This code is designed to calculate the mean reaction time (RT) for each subject in a dataframe. The code uses the groupby() method to group the data by the 'subject' column and then calculates the mean for each group using the mean() method.\n",
    ">\n",
    ">The resulting dataframe contains the mean RT for each subject. The index of the dataframe is the unique values in the 'subject' column, and the columns are the other numerical columns in the original dataframe.\n",
    ">\n",
    "> This code is useful when working with data that has multiple subjects and you want to calculate summary statistics for each subject. By using the groupby() method, you can easily calculate summary statistics for each group without having to manually subset the data.\n",
    ">\n",
    "> One possible way to improve this code would be to specify the column to calculate the mean for, rather than calculating the mean for all numerical columns. This would make the code more specific and reduce the risk of errors. Additionally, the code could be modified to calculate other summary statistics, such as the standard deviation or median, by using the appropriate method instead of the mean() method.\n",
    "\n",
    "First off, this shows how Copilot can be a great learning tool. It's giving us a clear explanation of what the code is doing, and teaching us a bit about how the `.groupby()` method works. It also suggests some improvements to the code, which are actually good suggestions.\n",
    "\n",
    "None of this explanation tells us directly why the code generates an error, but as a novice coder this probably provided you with greater understanding of what the code is actually doing. This will be helpful as we try to figure out what is going wrong. \n",
    "\n",
    "The first paragraph of Copilot's explanation *does* provide a subtle clue to us about the error, though. It notes that the code is grouping the data by the `subject` column. The error message also referenced `subject`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copilot `Fix This`\n",
    "\n",
    "If you select `Fix This` from the Copilot menu, you will see what's called a **diff**, as shown below. A diff is a way of showing the difference between two pieces of code. The code on the left (with a pink background) is the code you wrote, and the code on the right (with a green background) is the code that Copilot suggests. In this case, the suggested \"fix\" would not fix the problem. \n",
    "\n",
    "![](images/copilot_fix_this.png)\n",
    "\n",
    "\n",
    "The suggested code is doing two things differently from the original code. Firstly, it's suggesting that you assign the output of the command to a variable, and then print the variable. Assigning output to a variable and then printing it is in general good coding style, because we may want to use that variable again later in our code. But that won't fix the error. \n",
    "\n",
    "The other difference – which is subtle to a novice coder – is that the new code is referencing the column `Subject` rather than `subject`. Recall that Python is **case-sensitive**, meaning that `Subject` and `subject` are not the same thing. Copilot seems to be guessing that the error might be cause by a common mistake, which is to refer to a variable using the wrong case. \n",
    "\n",
    "In this particular situation, however, the error is not caused by a case-sensitivity error. The error is caused by the fact that the column `subject` doesn't exist in the DataFrame.\n",
    "\n",
    "So, you can click the `Discard` button to reject Copilot's suggestion, and the `Escape` key to exit the diff view.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](images/chat_icon.png)  Copilot `Chat` \n",
    "\n",
    " Another, really useful option is the `Chat` option, which you can option by clicking the `Chat` icon (shown above) in the Activity Bar (left side of VS Code). This allows you to have a conversation with Copilot about what you want to do. If you've used [Chat-GPT](https://chat.openai.com/) before, this will be familiar to you as it's essentially the same type of natural-language interface.\n",
    "\n",
    "There are different approaches to using Copilot Chat to help fix an error. One is to click in the cell that generates the error, and then click in the Copilot Chat input box, and typing: \n",
    "\n",
    "```\n",
    "the selected cell generates an error. how can i fix this error?\n",
    "``` \n",
    "\n",
    "In response to this prompt for the present error, I got the following response:\n",
    "\n",
    ">If you are getting an error with the selected cell, there could be a few reasons why. Here are some possible solutions:\n",
    ">\n",
    ">1. Check that the 'subject' column is present in the dataframe. You can do this by printing out the dataframe using the `print()` function and checking that the 'subject' column is present.\n",
    ">\n",
    ">2. Check that the 'subject' column is spelled correctly. If the column is misspelled, you will get a \"KeyError\" when trying to group by that column.\n",
    ">\n",
    ">3. Check that the 'subject' column is of the correct data type. If the 'subject' column is not a string or categorical data type, you may need to convert it using the `astype()` method.\n",
    ">\n",
    ">4. Check that the dataframe contains numerical columns. If the dataframe only contains non-numerical columns, you will get a \"DataError\" when trying to calculate the mean.\n",
    ">\n",
    ">5. Check that the dataframe does not contain missing values. If the dataframe contains missing values, you may need to remove them using the `dropna()` method before calculating the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Error with Copilot's Help\n",
    "\n",
    "These are actually really good responses, and they are provided in a logical order to go through in debugging. We could work through them in order, but — spoiler alert — the first suggestion actually leads to a solution. \n",
    "\n",
    "### Check that the 'subject' Column is Present in the DataFrame\n",
    "The first thing to do is to check that the column exists, and is spelled correctly. So let's start with that. Do you remember how to check the names of the columns in a pandas DataFrame? If not, you can write a Copilot prompt to help you out. In the cell below, write a prompt that will print the names of the columns in the DataFrame. Then run the cell, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participantID', 'trial', 'RT'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the column names of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to look at the first few rows of the DataFrame, which includes the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831\n",
       "3            s2      4  0.417988\n",
       "4            s2      5  0.371810"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third option, when using Jupyter notebooks with VS Code, is to click on the `Variables` button in the toolbar at the top of the notebook window. This will pop up a variable viewer in sub-window below your notebook. You can click on the variable names to see their values. For DataFrames, it actually shows a list of the columns in the window, and you can double-click on the variable name to see the contents of the DataFrame in another window, the **Data Viewer**. This view is similar to a spreadsheet. In fact, you can directly edit values in the Data Viewer. *You should never directly edit values like this*, however. Any steps you do manually are not documented in your code, and are not reproducible.  \n",
    "\n",
    "The screenshot below shows the variables and Data Viewer for the current context.\n",
    "\n",
    "![](images/inspectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Solution\n",
    "\n",
    "Using any of the three approaches above, when we look at the column names, we see that they are `participantID`, `trial`, and `RT`. The code that generated the error was trying to access a column called `subject`, which doesn't exist. It should be `participantID`. So we need to change the code to access the correct column name. Or, engineer our prompt to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trial        RT\n",
       "participantID                 \n",
       "s1               5.5  0.389548\n",
       "s2               5.5  0.444785\n",
       "s3               5.5  0.446009"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean rt for each participantID\n",
    "df.groupby('participantID').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, however the code is providing means for both columns in the DataFrame (`trial` and `RT`), not just for `RT` (sometimes the same prompt actually does select only `RT` but we'll explore when it doesn't). We can add to our prompt to tell it not to include `trial` in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean rt for each subject. Do not show the mean for trial \n",
    "df.groupby('participantID').mean().drop('trial', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above generated code does what we want. However, from the perspectives of coding style and efficiency, it's not optimal. Python executes this **chained command** from left to right. So, it first computes the mean for each column in the DataFrame, and then drops the column `trial`.\n",
    "\n",
    "It seems unnecessary to compute the mean for `trial` and then drop it. This isn't really Copilot's fault — we did explicitly tell it not to show the mean for trial, but it's not smart enough to know that we don't want to compute it in the first place; it seems to have interpreted our prompt as a literal sequence of commands.\n",
    "\n",
    "We can modify the prompt in a way that generates more efficient code, by being specific about the column that we do want, rather than what we don't want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    0.389548\n",
       "s2    0.444785\n",
       "s3    0.446009\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean for each participantID using the RT column\n",
    "df.groupby('participantID')['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By way of showing how sensitive Copilot is to the structure of your prompt, a slightly different (and arguably more logical) phrasing of the prompt above generates the less-efficient code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RT\n",
       "participantID          \n",
       "s1             0.389548\n",
       "s2             0.444785\n",
       "s3             0.446009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT for each participantID\n",
    "df.groupby('participantID').mean().drop('trial', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "One thing you may notice is that the result of the last command above is nicely-formatted when it is displayed, whereas the one before it is in a more \"raw\" format. This is not really important here, but it's worth understanding why the difference occurs. When you call a pandas DataFrame it prints in a nicely formatted output. However, when you call a pandas Series (which is a single column), it prints in a more detailed but less \"pretty\" way. \n",
    "\n",
    "In the output immediately above, the code created a DataFrame with two columns (`trial` and `RT`) and then dropped the `trial` column, but as such it remained a DataFrame and so was nicely formatted.\n",
    "\n",
    "In contrast, the output of using the `mean()` method on a single column (`RT`) in the cell above that is a Series.  \n",
    "<p><p>\n",
    "We'll worry about the formatting later, but it's good to understand why it happens because the distinction between DataFrames and Series often causes confusion and errors if it's not understood.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Continue Coding\n",
    "\n",
    "Having fixed that error, we can now move on with the steps in the instructions. The next step was to calculate the mean RT across subjects. Do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 42\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# calculate the mean rt across all subjects\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'"
     ]
    }
   ],
   "source": [
    "# calculate the mean rt across all subjects\n",
    "df['rt'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, when I tried this, I got another `key Error`, this time for `rt`. This is because the code is trying to access a column called `rt`, but the column name is actually `RT`. Again, let's start by trying to fix this ourselves, and then use Copilot if we get stuck. \n",
    "\n",
    "The code above selects the column in `df` called `rt` and computes its mean. However, if you look back to the listing of column names that we generated earlier, you'll see that the column name is actually `RT`. Remember that Python is **case sensitive**, meaning that capitalization matters: `RT` and `rt` are not the same. So we need to change the code to access the correct column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4267806816333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having fixed that error, let's move on to the next step, which is to calculate the 95% confidence intervals for the mean RT for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 46\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# calculate 95% confidence intervals for each subject\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39msem() \u001b[39m*\u001b[39m \u001b[39m1.96\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each subject\n",
    "df.groupby('subject').mean().apply(lambda x: x.sem() * 1.96, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we get `Key Error: 'subject'`, which is the same as the first error above. So again, Copilot is labelling the column incorrectly. We know that we can fix this by replacing `subject` with `participantID`, but it's a bit annoying that Copilot keeps making this error. On the other hand, many errors are actually human errors. We are prompting Copilot to do something for each  \"subject\", which then requires Copilot to know that by \"subject\" we really mean the column called `participantID`. Maybe we could engineer our prompt to be better instead, by referring to the column name directly. Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    5.008243\n",
       "s2    4.954111\n",
       "s3    4.952911\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each participantID\n",
    "df.groupby('participantID').mean().apply(lambda x: x.sem() * 1.96, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pink Elephants\n",
    "\n",
    "This is a frightening example of a Copilot **hallucination**. The above code generates a table of numbers, one for each participantID.  You might think this is a plausible result. However, there are a couple of problems. Firstly, confidence intervals (CIs) are typically reported as a pair of values. The 95% CIs reflect the *range* within which it is 95% likely that the true mean lies, so we need an upper *and* lower limits of the CI. These are typically the same amount plus or minus the mean (e.g., if the mean is 2, the 95% CIs might be 1.5 and 2.5). So given a conceptual understanding of what CIs are, we recognize that we need to modify the code to generate the upper and lower values of the CIs. \n",
    "\n",
    "Secondly, if you look back at the mean RT for each participant, they were in the range of .339 – .449. Again, confidence intervals reflect the range of possible true values for the mean, given the sample data.  So for our confidence intervals to have values around 5 s seems implausible, given the mean RTs are < 500 ms. We would expect the CIs to be perhaps 100-200 ms. So it seems like Copilot is calculating the CIs incorrectly.\n",
    "\n",
    "This highlights the critical importance of understanding not only what your code is doing, but what you are asking it to do. You should always check the output of your code to make sure it makes sense, and also make sure you understand what you are supposed to be doing with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copilot Chat to the Rescue\n",
    "\n",
    "Since Copilot Chat was helpful before, let's try using it to help us figure out what is going on. If we click on the `Chat` icon in the Activity Bar, we can type in a question to Copilot. In this case, I asked Copilot the following:\n",
    "\n",
    "> the highlighted code is supposed to compute the 95% confidence intervals of mean RT. However, the output values are incorrect. Can you please suggest code that correctly calculates the 95% confidence intervals, and provides both the upper and lower CIs in a table\n",
    "\n",
    "Copilot provided the answer below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> To correctly calculate the 95% confidence intervals for the mean RT and provide both the upper and lower CIs in a table, you can modify the existing code as follows:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# calculate mean and standard error of the mean for each participant\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "sem_rt = df.groupby('participantID')['RT'].sem()\n",
    "\n",
    "# calculate 95% confidence intervals for the mean RT\n",
    "ci_rt = sem_rt * 1.96\n",
    "\n",
    "# calculate upper and lower CIs\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "\n",
    "# create a table of the upper and lower CIs\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci})\n",
    "\n",
    "# print the table of CIs\n",
    "print(ci_table)\n",
    "```\n",
    "\n",
    ">> In this code, the `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` and `sem()` methods are used to calculate the mean and standard error of the mean for the 'RT' column for each group. The resulting series contains the mean and SEM for each unique value in the 'participantID' column.\n",
    ">> \n",
    ">> The `ci_rt` variable calculates the 95% confidence intervals for the mean RT using the formula `SEM * 1.96`, where `SEM` is the standard error of the mean.\n",
    ">> \n",
    ">> The `upper_ci` and `lower_ci` variables calculate the upper and lower CIs by adding and subtracting the `ci_rt` value from the `mean_rt` value, respectively.\n",
    ">> \n",
    ">> The `ci_table` variable creates a table of the upper and lower CIs using the `pd.DataFrame()` function.\n",
    ">> \n",
    ">> Finally, the `print()` function is used to print the table of CIs.\n",
    ">> \n",
    ">> This code should give you the desired output of a table containing the upper and lower CIs for the mean RT for each participant.\n",
    "\n",
    "If you move your cursor over the code that Copilot generated, you will see a `Copy` button appear. Clicking this will copy the code to your clipboard, so you can paste it into your notebook. We'll run this code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Upper CI  Lower CI\n",
      "participantID                    \n",
      "s1             0.430626  0.348470\n",
      "s2             0.496197  0.393373\n",
      "s3             0.515907  0.376111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate mean and standard error of the mean for each participant\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "sem_rt = df.groupby('participantID')['RT'].sem()\n",
    "\n",
    "# calculate 95% confidence intervals for the mean RT\n",
    "ci_rt = sem_rt * 1.96\n",
    "\n",
    "# calculate upper and lower CIs\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "\n",
    "# create a table of the upper and lower CIs\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci})\n",
    "\n",
    "# print the table of CIs\n",
    "print(ci_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this is great progress. We now have our output in a table with both upper and lower CIs, and we can see that the CIs are in the range we would expect. It wouldn't hurt to cross-check the formula that Copilot is using against a textbook or online resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Check Copilot's Code with Other Sources\n",
    "\n",
    "There's an old saying, \"once bitten, twice shy\". We've already seen that Copilot can generate code that is incorrect. So, it's a good idea to check the code that Copilot generates against other sources. In this case, we can look up the formula for calculating the 95% CI for the mean, and compare it to the code that Copilot generated.\n",
    "\n",
    "If we do a Web search for `confidence interval formula`, we will find that the results across all of the top hits indicate that the formula for calculating the 95% CI for the mean is:\n",
    "\n",
    "```python\n",
    "ci_upper = mean + 1.96 * (std / sqrt(n))\n",
    "ci_lower = mean - 1.96 * (std / sqrt(n))\n",
    "```\n",
    "\n",
    "where `mean` is the mean of the data, `std` is the standard deviation of the data, and `n` is the number of observations.\n",
    "\n",
    "However, Copilot's code multiplied 1.96 by `sem_rt`, which is the *standard error* of the mean. But if you remember (or look up) the formula for standard error, it is the standard deviation of the data divided by the square root of the number of observations. So, Copilot's code is correct, but it's using a different formula than the one we found online. But at least now we can be confident that the code is doing what we want it to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% CIs across all participants\n",
    "\n",
    "Our next instruction is to compute 95% CIs across all participants. Given our troubles above, we may not have much confidence that it will work the first time. But, let's start by copying the  phrasing that Copilot Chat used when describing its answer to the previous question, but adding in \"across all participantID\" to the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Upper CI  Lower CI\n",
      "participantID                    \n",
      "s1             0.430626  0.348470\n",
      "s2             0.496197  0.393373\n",
      "s3             0.515907  0.376111\n"
     ]
    }
   ],
   "source": [
    "# calculate the 95% confidence intervals for the mean RT across all participantID\n",
    "# and provide both the upper and lower CIs in a table\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "sem_rt = df.groupby('participantID')['RT'].sem()\n",
    "ci_rt = sem_rt * 1.96\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci})\n",
    "print(ci_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately Copilot doesn't seem to have understood \"across all participantID\", and it gave us CIs for each participant separately. So, let's try again, but this time we'll be more explicit about what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Upper CI  Lower CI\n",
      "RT  0.459111   0.39445\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean RT across all participantID\n",
    "# then compute the 95% confidence intervals for the mean RT across all participantID\n",
    "# and provide both the upper and lower CIs in a table\n",
    "mean_rt = df['RT'].mean()\n",
    "sem_rt = df['RT'].sem()\n",
    "ci_rt = sem_rt * 1.96\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci}, index=['RT'])\n",
    "print(ci_table) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better, and if we examine the code, we see that it's using the same formula as the (correct) code that Copilot generated for the previous step. \n",
    "\n",
    "The prompt above is an example of how **programmatic thinking** is required even when using an AI coding assistant. In order to get the deisred result, I had to break down the problem into smaller chunks. In this case, I told it to compute the mean across all participantID, and *then* compute the 95% CIs.\n",
    "\n",
    "Another prompt that also works is below; note that the output is formatted differently, but the values are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45911120518780957, 0.3944501580788572)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the upper and lower 95% confidence interval limits for RT across participantid\n",
    "df['RT'].mean() + df['RT'].sem() * 1.96, df['RT'].mean() - df['RT'].sem() * 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Python feature in this code that we haven't seen before is using a comma to separate two commands. This is a way of executing two commands in a single line of code. It's not a very common way of writing code, but as you can see in this example, it can be useful: the output is a Python `tuple`, which is an immutable, ordered collection of values. This is a good type to use when you have a pair of values that belong together, and the immutable nature of tuples means that you can't accidentally change one of the values. Furthermore, the ordering means you can access the values by their position in the tuple, which is useful in this case because, using this prompt, Copilot will always put the upper CI first and the lower CI second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formatting the output nicely\n",
    "\n",
    "The next instruction is to \"Print all of the above results to the screen, rounded to 2 decimal places and with accompanying text that indicates what each result is. Be sure that it is clear that RT is in seconds.\" In a typical workflow, we might want to get each of the above calculations working correctly, and then modify the code in those cells further to get nice-looking output. However, for explanatory purposes we will keep the above cells as they are, and copy the working prompts from above so that we can add instructions for formatting. \n",
    "\n",
    "Note that in the prompt below, the instructions are broken down into a sequence of steps, each of which is a separate line of the prompt. This helps with readability, and in our experience, it also increases the likelihood that Copilot will generate the code we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    trial    5.50\\nRT       0.39\\nName: s1, dtype:...\n",
       "s2    trial    5.50\\nRT       0.44\\nName: s2, dtype:...\n",
       "s3    trial    5.50\\nRT       0.45\\nName: s3, dtype:...\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT for each participantID rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df.groupby('participantID').mean().round(2).apply(lambda x: str(x) + ' seconds', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems almost right, but there are weird extra characters in there: `\\n`. As well, it is outputting the means for both `RT` and `trial`, even though we only asked for `RT`. \n",
    "\n",
    "At this point, we could try to fix this ourselves, but I can speak from experience in saying that that would be time consuming, and likely lead you down several incorrect paths. Let's try Copilot again. \n",
    "\n",
    "![](images/chat_icon.png) Click again on the Copilot Chat icon in the Activity Bar. Let's first ask for an explanation of the code. This is a complex line of code with four operations chained together, including an embedded `lambda()` function, which we haven't learned about yet. \n",
    "\n",
    "To get an explanation of the code, I first selected the entire line of code with muy curor. Then, in the Copilot Chat window, I typed `explain the highlighted line of code`. In response, I got the following explanation:\n",
    "\n",
    ">The highlighted line of code calculates the mean of all numerical columns in the dataframe `df` for each unique value in the 'participantID' column. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean for each group. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The `axis=1` parameter specifies that the function should be applied to each row of the dataframe.\n",
    ">\n",
    ">This code is useful when working with data that has multiple participants and you want to calculate summary statistics for each participant. By using the `groupby()` method, you can easily calculate summary statistics for each group without having to manually subset the data.\n",
    ">\n",
    ">The resulting dataframe can be used to create a summary table or plot of the mean values for each participant. The `apply()` method can be modified to add different strings or formatting to the mean values, depending on the desired output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is a good explanation of what the code is doing. But it doesn't provide a lot of insight into why the formatting is off, or why `trial` is included. So let's try asking Copilot a more specific question about the things we don't like about the code. I tried this prompt: \n",
    "\n",
    "```\n",
    "the highlighted code prints means for both trial and RT, but I want it to only print the mean RT for each participantid. suggest code to do what I want\n",
    "```\n",
    "\n",
    "In response, I got the following:\n",
    "\n",
    ">To print only the mean RT for each participantID, you can modify the existing code to select only the 'RT' column before calling the `groupby()` and `mean()` methods. Here's an example:\n",
    ">\n",
    "\n",
    "```python\n",
    "df.groupby('participantID')['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')\n",
    "```\n",
    "\n",
    ">\n",
    ">In this code, the `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean of the 'RT' column for each group. The resulting dataframe contains the mean RT for each unique value in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The resulting series contains the mean RT for each unique value in the 'participantID' column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">This code should give you the desired output of only the mean RT for each participantID, rounded to two decimal places and with the string ' seconds' added to each value.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that suggested code and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    0.39 seconds\n",
       "s2    0.44 seconds\n",
       "s3    0.45 seconds\n",
       "Name: RT, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('participantID')['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great - now we have exactly what we want, and the code is even conveniently telling use that the units are seconds.\n",
    "\n",
    "### Print Mean Across Subjects, Nicely Formatted\n",
    "Next we want to print the mean across all participants, formatted as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb Cell 71\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# calculate mean RT across participantid rounded to 2 decimal places\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# and provide accompanying text that indicates what each result is,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y105sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# and that RT is in seconds\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaron/3505/NESC_3505_textbook/3b-ai_assisted/multi_data_files.ipynb#Y105sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mRT\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mround(\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# calculate mean RT across participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried right-clicking, going to Copilot in the pop-up menu, and then selecting `Fix This`. This generated the following code:\n",
    "\n",
    "```python\n",
    "# calculate mean RT across participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "mean_rt = df.groupby('participantid')['RT'].mean().mean().round(2)\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantid'\n",
    "result_text\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantid'\n",
    "result_text\n",
    "```\n",
    "\n",
    "This reflects a phenomenon that seems to happen regularly with Copilot, which is that it repeats itself. Note that the last two lines of code are identical to the two lines before them. This is a bit annoying, but it's not a big deal. We can just delete the last two lines of code.\n",
    "\n",
    "But there's a bigger problem: if you look closely at the code, you'll notice that it's trying to group by `participantid`, but the column name is actually `participantID`. Again, you need to be paying close attention to the code, and details like capitalization. In this case, I was being sloppy with capitalization in my prompts. Even though I already realized that I had to use `RT` and not `rt`, Copilot initially let me get away with lazily typing `participantid` and not `participantID`. But now my sloppiness has come back to bite me.\n",
    "\n",
    "Since I think I understand where the error is coming from, it's more expedient to fix it myself, so I copy and paste the code from above (without the repeated lines), and then edit it to capitalize `ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.43 seconds is the mean RT across participantID'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT across participantID rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "mean_rt = df.groupby('participantID')['RT'].mean().mean().round(2)\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantID'\n",
    "result_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% CIs for Each Participant, Nicely Formatted\n",
    "Now that that is fixed, let's move on to the next step, which is to calculate the 95% confidence intervals for the mean RT for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    5.01 seconds\n",
       "s2    4.95 seconds\n",
       "s3    4.95 seconds\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each participantID rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df.groupby('participantID').mean().apply(lambda x: x.sem() * 1.96, axis=1).round(2).apply(lambda x: str(x) + ' seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% CIs for All Participants, Nicely Formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45911120518780957"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals across all participantID, rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df['RT'].mean() + df['RT'].sem() * 1.96, df['RT'].mean() - df['RT'].sem() * 1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
