{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30362093-e9da-4529-840a-72b4bf389912",
   "metadata": {},
   "source": [
    "# Segmentation into ERP epochs\n",
    "\n",
    "In this lesson we will learn how to segment continuous EEG data into epochs, time-locked to experimental events of interest. This is the stage at which we move from working with EEG data, to ERP data. Recall that *ERP* stands for *event-related potential* — short segments of EEG data that are time-locked to particular events such as stimulus onsets or participant responses. In the previous steps we removed artifacts from the continuous EEG data. Now, we will segment the data into epochs, and apply artifact correction to the segments, based on the ICA decomposition that we performed in the previous step, as well as using the AutoReject algorithm to automatically detect and remove bad epochs and channels that ICA may not fix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20585629-b838-4982-acba-90cbd9296461",
   "metadata": {},
   "source": [
    "## Import MNE and Read Filtered Data\n",
    "\n",
    "We will segment the band-pass filtered version of the continuous EEG data that we created in the filtering lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb1651-d022-4725-ab5f-97fa2dde8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level('error')  # reduce extraneous MNE output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Participant ID code\n",
    "p_id = 'N400_dataset_14'\n",
    "data_dir = 'data'\n",
    "\n",
    "raw = mne.io.read_raw_brainvision( 'data/' + p_id + '.vhdr', preload=True)\n",
    "raw_filt = mne.io.read_raw_fif(data_dir + '/' + p_id + '-filt-raw.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cfa89-ff27-4460-8d31-75578353417a",
   "metadata": {},
   "source": [
    "### MNE's events structure\n",
    "\n",
    "**Event codes** indicate when events of experimental interest occurred during the EEG recording. They are typically generated by the stimulus computer, and sent to the EEG recording computer at the same time that the stimuli are presented to the participant. Event codes may also mark when a participant made a response (such as a button press, or the onset of a vocal response), or other information such as the start of a new bock of trials or condition, rather than a specific stimulus. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenting the data into ERPs depends on these event codes, since they are what we time-lock to. To use them for ERP segmentation, we need to first extract the timing and identity of each code from the raw data, and store it in a NumPy array. Because event codes are numeric (for reasons explained below), we also need to define a mapping between these numbers and meaningful labels (such as what type of stimulus or experimental condition the code denotes). \n",
    "\n",
    "We use `mne.events_from_annotations()` to extract the event codes from the raw data and store them in a NumPy array called `events`. The function actually produces two outputs; the second is a dictionary mapping the event codes to labels, which we assign to `events_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, events_dict = mne.events_from_annotations(raw_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the first 10 rows of the `events` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd7b57-b814-435d-9119-698e439f1708",
   "metadata": {},
   "source": [
    "`events` is a NumPy array with 3 columns, and one row for each event code in the data. \n",
    "\n",
    "The **first column** contains the index of the event code in terms of the data array. Recall that the data were sampled at a rate of 500 Hz, meaning we have one sample (i.e., measurement) every 2 ms. So the values in the first column of `events` are not time measured in milliseconds, but \"time\" in terms of samples or data points. This is important to remember later, although MNE generally makes it easy to go between samples and more intuitive measures of time like milliseconds or seconds.\n",
    "\n",
    "The **second column** is usually zero, but is intended to mark the end time off an event, if the event code was send to the EEG system for a period of time. In practice it is rarely used, and we will ignore it.\n",
    "\n",
    "The **third column** is the event code itself, as an integer. We'll elaborate later on what each code means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### About Event Codes\n",
    "\n",
    "Most EEG systems receive event codes from the stimulus computer using an electronic communications protocol called **TTL**, or transistor-to-transistor logic. It's very simple and low-level, and is done via the parallel port of a computer (which is so low-level, computers almost never have these built in anymore). The reason this arcane system is still routinely used in EEG is that its timing is very precise, which means it is the best option to get millisecond-level synchronization between when the stimulus computer presents a stimulus, and when the event code is received by the EEG system. This level of precision is vital in EEG research because the effects of interest occur on a millisecond time scale. The impact of this system for us is that the event codes stored in an EEG data file are usually restricted to integers in the range of 1–255, because that is the (8 bit) resolution of the TTL protocol (i.e., this kind of connection can inherently only send this range of values). Some EEG recording software allows the experimenter to specify text labels for each numerical event code, based on what the numbers mean in that particular experiment. However, in most cases mapping between the numerical event codes and meaningful labels is something we do in preprocessing, as shown below.\n",
    "\n",
    ":::{note}\n",
    "\n",
    "A modern replacement for TTL signals is the [**Lab Streaming Layer**](https://labstreaminglayer.org/) (LSL), which is a software-based system for sending event codes and other data between computers. LSL involves one computer running an LSL server application, which other computers (or processes on the same computer) send data to via a network connection. LSL has a sophisticated way of synchronizing timing between multiple computers, which allows for good temporal precision. Besides not requiring computers that have parallel ports, LSL can aggregate data streams from a variety of sources, including stimulus presentation software, EEG and fNIRS systems, eye trackers, motion capture systems, and more. In the present data sets we use TTL codes, however MNE supports LSL and the processes demonstrated here are similar for LSL data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931733b-b076-4bae-a30f-c0b704b0ff7b",
   "metadata": {},
   "source": [
    "### The Event Dictionary \n",
    "\n",
    "When MNE reads the event codes from a raw data file, it does a step that isn't always intuitive. Event codes in raw data files can take a variety of forms, depending on the software that was used to record the data. MNE searches through the raw data, and finds each unique event code (keeping in mind that event codes typically indicate a category of stimuli, or experimental condition, not the identity of individual stimuli or trials). MNE treats the event codes as strings, even if they are all numeric. MNE then assigns each unique event code an integer value. This mapping between original event codes and integers is stored in a dictionary called `events_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643791e0-47d0-40df-baa8-e4cd768d7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above dictionary, the original event codes are the dictionary keys (on the left of the colons). You can see that the first two entries are not of experimental interest, but simply note the start of recording. The other event codes were originally numeric, but the recording software pre-pended `Stimulus/S` to the start of each one. MNE has simply matched each one to an integer, so the event codes used in MNE don't match the original event codes. This is why `events_dict` is critical to ensuring that you map the right event codes to the each event of experimental interest. Another step is required, though, because we need a way of mapping from the the codes that MNE is using in the data, to the labels for the events that make sense to us in terms of the experiment (e.g., different stimulus types, response onsets, etc.). \n",
    "\n",
    "There is actually a workaround for this. In the present case, we imported the filtered data that we created in a previous lesson. If instead we had applied `mne.events_from_annotations()` to the original `raw` data file, MNE would be able to parse the event codes, and will assign them the same integer values that they had in the original data file. This is because the original data file was in the BrainVision format, which stores the event codes in a way that MNE can read. However, if you apply `mne.events_from_annotations()` to the `raw_filt` data file, MNE will not be able to parse the event codes, because the data file is in the `.fif` format, which stores the event codes differently. In this case, MNE will assign new integer values to the event codes, starting at 1 for the first event code it finds in the file, as we see here. \n",
    "\n",
    "For reference, let's see the difference when we read the original raw file. Since we only want the event codes, and not the data,  we can speed the process up by setting the kwarg `preload=False`. This tells MNE to read the metadata from the file, but not the data itself. This also saves memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_brainvision( 'data/' + p_id + '.vhdr', preload=False)\n",
    "events_raw, events_dict_raw = mne.events_from_annotations(raw)\n",
    "events_dict_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice it would make sense to read in the original raw file here to get the event codes. However, we will continue with the filtered data, because it provides an opportunity to demonstrate how to re-map information between two Python dictionaries, which is a useful thing to learn about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eceb9c-4cf6-4ecb-955c-6e0b7f498002",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{admonition} Background on the Experiment that Generated These Data\n",
    "\n",
    "This data set was collected while the participant viewed a series of pictures of objects on a computer screen. One second after each picture was presented, a spoken word was played over a speaker. The word was either the name of the pictured object, or some other word. Based on prior research, we predicted an **N400** ERP component for the mismatch trials relative to those on which the picture and word matched. In other words, the experimental contrast we are interested in is between **Match** and **Mismatch** trials.\n",
    "\n",
    "The N400 is a component first discovered by [Kutas & Hillyard (1980)](https://dx.doi.org/10.1126/science.7350657), in response to sentences that ended in a word whose meaning was not predicted given the preceding words in the sentence. For example, the sentence *I take my coffee with milk and dog.* would elicit an N400 at the word *dog*. More than 40 years of subsequent research has shown that the N400 is a marker of brain processes involved in integrating new information into an ongoing context that people maintain of words and concepts — or in technical terms, *semantic integration*. Violations of expectations related to the meaning of stimuli evoke an N400 response. In the present experiment, we did not use sentences, however each picture created a context and the subsequent word either fit (matched) or did not fit (mismatched) that context. \n",
    "\n",
    "Although there were really only two experimental conditions in this experiment (match and mismatch), as you  there are a lot more than two event codes in the `events` array and `events_dict` dictionary above! This is because in this study, the experimenters coded details of the stimuli in great detail. This is common in research, where we have one central research question, but perhaps other questions relating to more fine-grained details of the stimuli. As well, the stimuli may vary in ways that are not of experimental interest, but are properties that we would like to control for. For now we will label each event code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Label Event Codes\n",
    "\n",
    "We can define a dictionary that maps labels onto each event code of interest. As you can see below, there are 4 event codes associated with Match trials, and 4 associated with Mismatch trials. Later we will merge them before examining the ERPs, but for now we will label each one separately. This preserves the more detailed information, in case later we decide we want to break the data down in a more fine-grained fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c61a4b-aa97-4373-a554-6b2e006b2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_mapping = {'PicOnset':1, 'RespPrompt':2, 'CorResp':3, 'IncorResp':4, 'RespFeedback':5, 'unused':7,          \n",
    "                 'Match/A':111, 'Match/B':211, 'Match/C':112, 'Match/D':212,\n",
    "                 'Mismatch/A':101, 'Mismatch/B':201, 'Mismatch/C':102, 'Mismatch/D':202\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to map between `events_dict` and `event_mapping`. The first thing we'll do is swap the keys and values in `event_mapping`, because once we extract the original, numerical event codes from `events_dict` we will want to use them as keys to index into `event_mapping` so that we can find the corresponding labels. We can do this with a dictionary comprehension (which is like list comprehension, but for dictionaries). `event_mapping.items()` will generate two outputs: the keys and the values of the dictionary. We can then swap them by putting the values first, and the keys second, separated by a colon. We then wrap this in curly braces to indicate that we are creating a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap keys and values in event_mapping\n",
    "event_mapping = {v:k for k,v in event_mapping.items()}\n",
    "event_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is extract the numerical event codes from `events_dict` (e.g., the`'1'` in `'Stimulus/S  1': 3`). We only need to do this for event codes that start with `'Stimulus/S`, so we can select only the keys in `events_dict` that match this string, then strip it from each key to get the numerical event code. We can then use this numerical code to index into `event_mapping` to get the label for that event code. We can then assign the label to the `name` key in `events_dict` for that event code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dictionary to map experiment labels to MNE's event codes\n",
    "event_id = {}\n",
    "\n",
    "for key, value in events_dict.items():\n",
    "    # select only the keys in `events_dict` that match this string\n",
    "    if 'Stimulus/S' in key:\n",
    "        # strip the leading text from the key to get the numerical event code\n",
    "        orig_event_code = int(key.split('/S')[1])\n",
    "        # \"value\" is the integer event code that MNE assigned to each event code it found in the data\n",
    "        # we map this value to a key that corresponds to the original event code, \n",
    "        # and add this key:value pair to event_id\n",
    "        event_id[event_mapping[orig_event_code]] = value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c5ecd-7612-4696-be47-d0158dd67a73",
   "metadata": {},
   "source": [
    "### Plot Events Over Time\n",
    "\n",
    "MNE provides a useful function, `mne.viz.plot_events()`, which will read an events array and plot the timing of event codes over the time, with different rows and colors for each event type. We have to pass the sampling rate (`raw.info['sfreq']`) as the second argument so that MNE knows how to convert the samples in the `events` array to units of time. We also pass `event_mapping` so that the plot has a meaningful legend.\n",
    "\n",
    "This plot can be very useful to understand the timeline of an experiment, and also to confirm that the types and timing of event codes Control what was expected based on the design of the experiment. In the present experiment, all three sentence types were randomly intermixed, so the plot below is consistent with this. \n",
    "\n",
    "Note that it's not necessary to use `plt.subplots()` before running any MNE plot routine. However, in some cases, such as this one, MNE's default plot size is not optimal for what is being plotted, so `plt.subplots()` allows us to specify the figure size. Note that when we run the MNE plot command, we don't apply a Matplotlib axis method, but instead pass the `ax` pointer to the subplot to MNE's plot command using the `axes=` kwarg. Many of MNE's plotting commands support this kwarg, but not all (since some MNE plots actually create figures with multiple subplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de013044-9721-44fe-beb0-a0aa1e091528",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 5])\n",
    "\n",
    "mne.viz.plot_events(events, raw_filt.info['sfreq'],  \n",
    "                    event_id=event_mapping,                    \n",
    "                    axes=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot of event codes over time can be very useful in ensuring that the event codes in your experiment occurred as expected. This is especially important to check when you're first pilot-testing an experiment, before you collect data from lots of participants. It's also useful simply to visualize and understand the structure of an experiment. \n",
    "\n",
    "For example, in the plot above the bottom three rows show lots of dots (event codes) quite regularly over the duration of the data collection. The legend tells us these correspond to picture onsets, response prompts, and correct responses. This makes sense since pictures appeared on every trial, and the participant was prompted for a response on every trial. And, participants performed the task reasonably well, so the majority of responses were correct; we can see a few incorrect responses along the line marked `4` on the *y* axis. The other event codes occur less frequently, and at somewhat random intervals – these are the individual match and mismatch trials, whose order was randomized in the experiment. However, if you look closely you can see that the experiment was broken into two blocks: the `A` and `B` trial types occurred in the first half of the experiment, while the `C` and `D` trial types occurred in the second half."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85ac3a-a024-4c2c-949e-0130f9b9eeb7",
   "metadata": {},
   "source": [
    "### Segment the data into epochs\n",
    "\n",
    "Having extracted our event codes, and mapped them to labels, we are now ready to split the continuous, filtered raw EEG data into epochs time-locked to the event codes of interest, as defined in the `event_mapping` dictionary we created above. To do this we use `mne.Epochs()`, which creates an object of the class `Epochs`. The [API](https://mne.tools/stable/generated/mne.Epochs.html) for this function is: \n",
    "\n",
    "    mne.Epochs(raw, events, event_id=None, tmin=-0.2, tmax=0.5, baseline=(None, 0), picks=None, preload=False, reject=None, flat=None, proj=True, decim=1, reject_tmin=None, reject_tmax=None, detrend=None, on_missing='raise', reject_by_annotation=True, metadata=None, event_repeated='error', verbose=None)\n",
    "\n",
    "\n",
    "We don't need to specify all of the arguments listed in the API, but a number of them are necessary; the first 5 of these are *positional* arguments, meaning that the first 5 arguments positions are required, must occur in the order shown, and must have specific contents:\n",
    "- the first is the raw data. We will pass the filtered raw data.\n",
    "- the next two arguments are the events array, and the mapping of events to labels (we'll use `event_mapping`)\n",
    "- the fourth and fifth arguments are the start and end times of each epoch (`timn` and `tmax`), relative to the event code. Typically the minimum (start) time is a negative number, because for reasons explained below we want a *baseline* period to compare to the activity after the event code (typically 50-200 ms, but sometimes longer). The end time depends on the timing of the ERP components you expect to occur. Some types of stimuli and experiments (such as studies of attention, or face processing) may only be interested in ERPs that occur within, say, the first 500 ms after stimulus presentation. In language studies, interesting effects often occur up to 1 s or even longer after a word is presented. An important thing to note is that  times in MNE are always specified in *seconds* (which is a bit counter-intuitive because we commonly talk about the timing of ERPs in milliseconds).\n",
    "\n",
    "After these 5 required positional arguments, there are many kwargs we can specify. For our purposes, the defaults for most of these are fine. However, we will specify two additional kwargs: \n",
    "\n",
    "The `baseline` kwarg specifies what time period to use as the baseline for each epoch. The baseline is the period before the stimulus onset, and it is used to define \"zero\" voltage for each trial. This is necessary because the measured electrical potentials can drift quite a lot over the course of the experiment (even after we filter out the lowest-frequency drift), and artifacts can affect absolute microVolt values as well. So the absolute microVolt values for any given epoch might be rather different from other epochs, due to drift. By subtracting the mean amplitude over the baseline period from each trial (and for each channel), we \"centre\" the measurements for that trial such that the potentials after the onset of each event code reflect the deviations of our measurements from the baseline period. Put another way, the measurements of each epoch reflect any changes in electrical potential that occur after the event code, relative to the baseline period before it. We use `(None, 0)` for the baseline to specify the time period from the start of the epoch to the time of the event code.\n",
    "\n",
    ":::{note}\n",
    "It's worth noting that subtracting the baseline like this is not always necessary, or desirable. Another approach is to leave the baseline untouched at the epoching stage, and worry about it later. In particular, there is an approach called <em>baseline regression</em> (<a href=\"https://onlinelibrary.wiley.com/doi/10.1111/psyp.13451\">Alday, 2019</a>) in which the mean amplitude of the baseline on each trial is used as a predictor in a regression model, which allows one to \"regress out\" the baseline on a trial-by-trial basis rather than subtracting it. This can be particularly useful in certain cases, such as when the baseline period isn't actually \"silent\" but contains some activity of interest (e.g., a previous word when reading a sentence or listening to a story; see e.g., <a href=\"https://dx.doi.org/10.3389/fpsyg.2022.668276\">Andersson et al., 2022</a>). However, the standard baseline subtraction approach is valid in most cases and we will use it here. :::\n",
    "\n",
    "We also include the `preload=True` kwarg. As with `raw` data, MNE tries to save memory by not keeping the epoched data in memory unless it is needed. However, below we will need it and so we force MNE to store this in the data here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756ade3-072b-4724-858a-1f7f90245d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoching settings\n",
    "tmin =  -.200  # start of each epoch (in sec)\n",
    "tmax =  1.000  # end of each epoch (in sec)\n",
    "baseline = (None, 0)\n",
    "\n",
    "# Create epochs\n",
    "epochs = mne.Epochs(raw_filt,\n",
    "                    events, event_mapping,\n",
    "                    tmin, tmax,\n",
    "                    baseline=baseline, \n",
    "                    preload=True\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2d426-5c12-4bc2-a3e9-4349df67f67b",
   "metadata": {},
   "source": [
    "If we ask for the value of `epochs` we get nice, tidy output with a summary of the contents of the data structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49c124-12ff-43b4-963f-56ae392a772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3884e-9919-40f2-bbfd-32735cd1fe17",
   "metadata": {},
   "source": [
    "Epochs can be accessed in a variety of ways, all using square brackets `epochs[]`. \n",
    "\n",
    "If we use an integer, we get the epoch at that index position (epochs are numbered from zero to the total number of epochs, in the order that the event codes occurred in the raw data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cc55b-9643-4251-99d1-da87b963f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b25008-cd6e-4c5c-8b13-caa697595a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842a645-4673-492d-83b1-dda91e103c7b",
   "metadata": {},
   "source": [
    "Alternatively, we can access all of the epochs associated with a particular event code, using the label we assigned to the code using `event_mapping`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b8f35-52d1-45bf-b7bd-3029548b48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['Match/A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db42e53-7469-4785-97d3-cee034316976",
   "metadata": {},
   "source": [
    "These two methods can be combined to select a specific event out of those in a condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845dc13-4026-4000-a32a-978a78717a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['Match/A'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc19a26-0a64-4a2e-8517-07efbe74ed28",
   "metadata": {},
   "source": [
    "If we pass multiple condition labels, then we will get all epochs in each of the conditions specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94cee1-bdba-43bf-bab2-c8b09237bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['Match/A', 'Match/B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ad4d1-062f-4348-b3c6-b8a1331bd734",
   "metadata": {},
   "source": [
    "MNE also recognizes the `/` separator for condition labels: the string before the `/` is treated as a more general category, with the string after the `/` treated as subsets of that category. What this means is that we can use only the string before the `/` to get all epochs from that category (all that have that string before the `/`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c2bcb-ae82-4098-9a20-bf936c658473",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['Match']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f50f2-d19a-48a7-8378-828f8a78d1f0",
   "metadata": {},
   "source": [
    "### Visualize average ERP across all conditions before artifact correction\n",
    "\n",
    "Here we create a plot averaged across all trials, and showing all electrodes on a single axis. Plotting all electrodes on one axis is called a **butterfly plot**; the name may seem strange but when you use it to plot data from lots of sensors (especially MEG data), it does [look somewhat like a butterfly](https://mne.tools/dev/_images/sphx_glr_90_phantom_4DBTi_001.png). \n",
    "\n",
    "\n",
    "We do this before removing ICs, so that we can compare with post-ICA below to see the effect of artifact removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898a5cf-69e7-4002-b503-ac6c939ba3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.average().plot(spatial_colors=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471f348-9074-4d0a-86f2-424473b594b2",
   "metadata": {},
   "source": [
    "The above plot shows strong evidence of ocular artifacts in the data: the amplitude scale is on the order of 100 µV, whereas real EEG is rarely more than 10–20 µV, and the largest amplitude values are in channels around the eyes (you can tell this by matching the colours of the lines in the plot with those of the channel locations on the inset showing the electrode layout)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c606348-b145-40be-87dc-35f2912cace3",
   "metadata": {},
   "source": [
    "### Scalp topography maps\n",
    "\n",
    "As we did with ICA components, we can plot the EEG potentials over the scalp using the `.plot_topomap()` method. This will confirm that the artifacts are focused over the electrodes close to the eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b81eb1-aacd-4a3c-9257-68e319113040",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Specify times to plot at, as [min],[max],[stepsize]\n",
    "times = np.arange(0, tmax, 0.1)\n",
    "\n",
    "epochs.average().plot_topomap(times=times, average=0.050);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5a55d-85e2-486b-b961-39b816c33a35",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply ICA correction to epochs\n",
    "\n",
    "To recap, we have created two different `Epochs` objects: \n",
    "- `epochs_ica`, with 1 s segments of the entire raw file, which we fit ICA on to identify artifacts\n",
    "- `epochs`, with segments time-locked to each event code of experimental interest\n",
    "\n",
    "Although we fit ICA to the `epochs_ica` data, we can actually *apply* this set of independent components to the `epochs` data. This is because ICA was fitted to the entire raw data set, and `epochs` is just a subset of that original raw data — so the effects of any ICs we marked for exclusion above will be removed from `epochs` with the `ica.apply` method. \n",
    "\n",
    "As with many MNE methods (such as filtering, as we saw earlier), the `ICA` `.apply()` method operates on data in-place, meaning it alters the data that is passed to it. In general, my preference is to make copies of data when applying transofrmations to the data, so here we chain the `.copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcb9e1-c4f0-4ff5-aeb2-252d8bfdb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.read_ica(data_dir + '/' + p_id + '-ica.fif')\n",
    "\n",
    "epochs_postica = ica.apply(epochs.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a834ab8-5f03-49b4-9349-518f93ed757d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize average ERP across all conditions after artifact correction\n",
    "\n",
    "We create the same butterfly plot that we did above, prior to artifact removal, so that we can see if and how the data were cleaned up. Compared to the previous plot, we can see that artifacts have been successfully removed, and the data look more like typical ERP data:\n",
    "- the large-amplitude deflections, largest at frontal channels, are no longer present\n",
    "- the amplitude scale (*y* axis) is in the range typical of ERPs\n",
    "- a series of early peaks typical of responses to visual stimuli are present (a first, small, peak around 75 ms, followed by a larger positive peak around 150 ms and a negative peak around 225 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae2b17-983b-44df-a9d5-0832f11a66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_postica.average().plot(spatial_colors=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7004a-5bc5-4f98-ade4-7974333dbaa5",
   "metadata": {},
   "source": [
    "### Scalp topography maps\n",
    "\n",
    "We saw this plot above, but now the scalp distribution of the electrical potentials shouldn't be concentrated over the eyes. \n",
    "\n",
    "We can also provide a bit more information about how these plots are drawn. We plot topo maps at 100 ms steps from the onset of the code up to the end of the epoch. The `average` kwarg specifies that each plot will reflect the average over a 50 ms time window, centered on each time point for which a plot is drawn. In other words, the plot labeled `0.100 s` reflects the average between 50–150 ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bc59b-f75b-47c4-a3f3-b58a15a809d1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Specify times to plot at, as [min],[max],[stepsize]\n",
    "times = np.arange(0, tmax, 0.1)\n",
    "\n",
    "epochs_postica.average().plot_topomap(times=times, average=0.050);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59194a48-cf39-4c75-8be1-92b8cee3a281",
   "metadata": {},
   "source": [
    "## Save epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5b482-018e-4cba-a69d-320dac31611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_postica.save(data_dir + '/' + p_id + '-epo.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476a03b-83aa-453d-9fdf-9d739bad7153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
