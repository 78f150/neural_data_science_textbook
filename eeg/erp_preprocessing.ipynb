{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08eea78b-5a55-47ec-a22a-226d524f2454",
   "metadata": {},
   "source": [
    "# EEG-ERP Preprocessing\n",
    "---\n",
    "## Learning Objectives\n",
    "- Be able to describe the standard steps in preprocessing EEG data for ERP analysis, including filtering, visual inspection, automated artifact detection and removal using independent components analysis, bad channel removal and interpolation, re-referencing, and averaging\n",
    "- Be able to describe the motivation for each of these preprocessing steps\n",
    "- Be able to perform each preprocessing step using MNE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db213772-df03-4760-b7a6-bc2a3650059a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "**Preprocessing** is a series of signal processing steps that are performed on data prior to analysis (EDA and/or statistical analysis) and interpretation. In virtually all forms of neuroimaging data, including EEG and MEG, preprocessing is necessary in order to remove noise and obtain a clean signal of interest. In the case of EEG, the data recorded from the scalp are inevitably a mixture of signals generated from the brain (which we likely care about), and other signals generated by sources other than the brain (which we generally don't wish to interpret). \n",
    "\n",
    "When they first learn about preprocessing, some people think it sounds a lot like cheating — \"doctoring\" or \"cooking\" the data to engineer a specific pattern of desired results. This is *not* the case, however. Preprocessing steps are carefully designed and implemented based on our understanding of the source and nature of particular sources of noise, as well as our understanding about the nature of the electrical activity generated by the brain. Because the skull is such a poor conductor of electricity, the amplitude of EEG signals recorded from the scalp is very small. In contrast, the amplitude of signals from noise sources — especially from the muscles and eyes — are often an order of magnitude or more larger. Thus if we fail to remove these known sources of noise from the data, it would be unlikely that we would detect the brain activity at all, and at best our ability to do so and make valid interpretations would be greatly diminished. In other words, ***preprocessing is an essential step in EEG analysis***.\n",
    "\n",
    "In this lesson we will describe each standard step in preprocessing EEG data for ERP analysis, including why it is done, and how, using the MNE package. A script that runs a series of preprocessing steps on data is often called a **piepline**; often this term is used to also include the entire proces from transferring data from the EEG system to a server or other long-term storage, preprocessing, and statistical analysis. The present script is an example of a **preprocessing pieline**.\n",
    "\n",
    "### Sources of noise in EEG\n",
    "\n",
    "In EEG, sources of noise can be physiological and non-physiological.\n",
    "\n",
    "**Physiological** sources of noise include muscles (especially face and neck muscles, which generate electrical potentials when contracting and relaxing), the eyes (which create distinctive signals both during blinks, and when the eyeballs move), and sometimes heartbeats (the heart produces strong, distinctive electrical signals as commonly measured with the electrocardiogram, or EKG) and breathing; the latter two sources typically are more of a problem for MEG than EEG data.\n",
    "\n",
    "**Non-physiological** sources include artifacts generated when electrodes move relative to the scalp, when the electrode wires move, and ambient electromagnetic noise. Electromagnetic noise is created by virtually any device that uses electricity (except some battery-powered devices). In North America and some other parts of the world, **line voltage** — the alternating current that is provided through wired electrical outlets — oscillates at 60 Hz; in Europe and other parts of the world, line voltage alternates at 50 Hz. Thus depending on where the EEG data were recorded, they will likely contain a fairly distinct peak in the frequency spectrum at 50 or 60 Hz. While line noise is the most common source of electromagnetic interference, noise at other frequencies can also be produced by other equipment near the neuroimaging system (though sometimes this may be in another room or another floor of the building, and difficult to identify), or even stronger, transient sources (such as the 2-way radio of a passing truck).\n",
    "\n",
    "We commonly refer to particular types of noise from known sources as **artifacts** in EEG. Thus you may see reference to *eye blink artifact*, *line noise artifact*, etc.. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbabeb5-0ed2-48e2-b4f6-6212f8b4580d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ddc56-2655-4f02-8b13-96a47db5da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level('error')  # reduce extraneous MNE output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d028a-be9d-4059-a90e-9bd1eb377252",
   "metadata": {},
   "source": [
    "## Define experimental and preprocessing parameters\n",
    "\n",
    "In the single unit chapter, we started the practice of defining experimental parameters as variables at the top of a notebook. This is good practice because the values are then defined when you need them. As well, it's good practice to define all of these parameters at the top of the file, rather than in the cell where you first need to use them. This is because, if later you want to change a parameter and re-run your notebook, it's easy to find all of the parameters, rather than scrolling through the script to find them. As well, when you report your results (e.g., in the Methods section of a paper), many of these parameters are things that you should include in your report. Defining them all at the top of a script makes it easy to find these values when you're writing up your study. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Best practices in EEG/MEG reporting</h3>\n",
    "    \n",
    "Especially for people who are new to any field of neuroimaging, there can be an overwhelming array of technical information relating to how the data were collected, preprocessed, and analyzed. This can make it challenging to know how, or what, to report. Fortunately, leaders in the field have reached a general consensus on this, and have published guidelines for reporting EEG and MEG study results. The most recent of these is from [Pernet and colleagues (2020)](https://www.nature.com/articles/s41593-020-00709-0) and is endorsed by the Organization for Human Brain Mapping.    \n",
    "    \n",
    "</div> \n",
    "\n",
    "Below we define all the parameters we'll use in this preprocessing script. We'll explain them in more detail as we reach each step in the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291be9cb-2fa8-4c6b-abd1-ed695fe04ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant ID code\n",
    "p_id = 'P4'\n",
    "\n",
    "# Electrode position file\n",
    "montage = 'standard_1005'\n",
    "\n",
    "# Filter settings\n",
    "low_cut = 0.1\n",
    "hi_cut  = 30\n",
    "l_trans_bandwidth = 'auto'\n",
    "h_trans_bandwidth = 'auto'\n",
    "filter_length='auto'\n",
    "filter_method = 'fir'\n",
    "\n",
    "# ICA settings\n",
    "ica_low_cut = 1.0       # For ICA, we filter out more low-frequency power\n",
    "ica_random_state = 42   # ensures ICA is reproducable each time it's run\n",
    "ica_n_components = .995     # Specify n_components as a decimal to set % explained variance\n",
    "ica_zthresh = 3.291     # USed to automatically determine which ICA components to reject \n",
    "\n",
    "# Event codes\n",
    "event_id = {'video1':1, 'video2':2,\n",
    "            'video3':3, 'video4':4,\n",
    "            'video5':5, 'video6':6,\n",
    "            'rest_start':7, 'rest':8,\n",
    "           }\n",
    "\n",
    "# Epoching settings\n",
    "tmin = -1.0  # start of each epoch (in sec)\n",
    "tmax =  1.0  # end of each epoch (in sec)\n",
    "baseline = None  #(None, 0)\n",
    "detrend = 0\n",
    "reject = None\n",
    "flat = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f7042-ea37-49cd-be79-efb682172e55",
   "metadata": {},
   "source": [
    "## Import raw data\n",
    "\n",
    "This is just the same as in the previous lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5639c-bc3b-43c0-90af-336293f86d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = 'data/' + p_id + '.vhdr'\n",
    "\n",
    "raw = mne.io.read_raw_brainvision(raw_file, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a3671-436f-4089-8c97-d518c3d61096",
   "metadata": {},
   "source": [
    "In this particular data set, the EEG cap was disconnected before the recording was stopped. This resulted in noise at the end of the file that doesn't reflect human EEG. This causes problems later, so we will crop the data here to prevent problems later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a68456-f97d-4bfe-9914-25ab923151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.crop(tmax=1340);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57d126-d534-4a36-bee3-ea29daa285b0",
   "metadata": {},
   "source": [
    "## Set electrode positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754a22e-858f-43a4-9875-dde14a95b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf7f7a-1c95-4293-bfbe-8a3864892a6b",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "As described in the previous section on [Time and Frequency Domains](./time_freq), a complex time-varying signal like EEG can be represented as a combination of sine waves of many different frequencies. Human EEG largely comprises signal power in a range of frequencies from 1–30 Hz; there is some evidence that higher frequencies may also carry important neurophysiological information, however in most EEG studies — and certainly in ERP studies — the vast majority of research questions concerns EEG signals in the 1–30 Hz frequency range. \n",
    "\n",
    "Sources of noise also manifest as oscillating frequencies that are picked up by EEG. In particular, *low frequency noise* comes from sources such as movement of the head and electrode wires, and perspiration on the scalp, while *high frequency noise* comes from sources including electromagnetic interference, and muscle contractions (especially facial and neck muscles). The frequency of these sources of noise may overlap with the 1-30 Hz EEG nad of interest, but in general they tend to be lower and higher, respectively, than human EEG. This means that by reducing the power of the signal at the frequencies above and below the range of experimental interest, we can reduce noise with minimal impact on the signals of interest. This process is called **filtering**.\n",
    "\n",
    "Filtering typically occurs at two points in the EEG pipeline: first at the time the data are recorded, and secondly during preprocessing. When EEG data are collected, the EEG amplifier will at the very least have a filter that cuts off frequencies that are higher than a certain threshold. This is called the **low pass filter cutoff**, because the filter \"passes\" lower frequencies through, but attenuates (reduces) higher frequencies. A low pass filter is absolutely *necessary* during digital recording of EEG (or any signal), because of a phenomenon known as **aliasing**. This occurs when a high-frequency signal is sampled at a rate lower than the frequency of the signal, and the result is an artifact (an artificial signal that distorts our true signal) at a much lower frequency than the actual high-frequency source. \n",
    "\n",
    "### Aliasing\n",
    "\n",
    "Simply knowing that aliasing causes high-frequency noise to be represented in the data as low-frequency artifacts — and that for this reason it's important to use a low-pass filter — is the most critical thing for someone doing EEG research. However, it's good to understand this phenomenon a little deeper. \n",
    "\n",
    "For example, in the current data set the EEG was recorded with a sampling rate of 500 Hz, meaning we obtained a measurement from each electrode every 2 ms. This is a sufficient sampling rate to detect an EEG signal at 30 Hz, because over the course of each cycle of the 30 Hz oscillation (e.g., from one peak to the next), which would last 1/30th of a second, we would have 500 / 30  $\\approx$ 17 measurements of the waveform — so we should have enough samples to accurately reflect the shape of the oscillating sine wave. \n",
    "\n",
    "In contrast, imagine that during the recording, there was an electromagnetic (noise) signal present in the environment that oscillated at 1700 Hz. Thus in 1 second, the noise signal would have 1700 oscillations, but our EEG amplifier could not detect this, since it is only sampling 500 times per second. In fact, 3.4 oscillations of the noise waveform would occur between every sample acquired by the EEG amplifier. Since 1700 is not an even multiple of 500, each sample acquired by our EEG amplifier would also capture a different phase of the 17000 Hz oscillation — sometimes its peak, sometimes its trough, and sometimes somewhere in between. When we \"connect the dots\" between these samples to draw our measured EEG signal, these measurements at different points in the oscillation will end up looking like a much lower-frequency oscillation. **This is shown in the figure below.**\n",
    "\n",
    "![aliasing figure]()\n",
    "\n",
    "The highest frequency that one can accurately record at a given sampling rate is called the **Nyquist frequency**. This can be defined as either 1/2 or 1/3 of the sampling rate. In general, you should use 1/3 because it is safest. Using 1/2 is acceptable only if you can guarantee that your noise sources and your signal are *phase locked*, meaning (in a simplified way) that their peaks and troughs are synchronized with each other. Since we can't guarantee this in real-world situations where noise is unpredictable, the 1/3 rule should be used.\n",
    "\n",
    "### Offline filtering\n",
    "\n",
    "**Offline** is a term that is generally used in EEG to refer to processing steps that are applied after the data are collected, in contrast to **online** processing that is applied when data are collected. So, the low-pass filter used during recording to prevent aliasing is an example of an online filter, while filtering that we apply in a script like this is offline filtering. \n",
    "\n",
    "Offline filtering serves to remove more noise from the data than online filtering. In general, EEG researchers prefer to record with a wider range of filter settings, in part because filters can cause distortions to the data, particularly if the cutoffs are too close to the range of frequencies of interest. Any online filter that is applied to the data is permanent, since the data are originally recorded that way — there is no \"undo\" option. In contrast, with offline filtering one can apply different filters and observe the results on the data, and re-load the original data and use different filter settings if necessary. \n",
    "\n",
    "### Offline filter settings\n",
    "\n",
    "We defined our filter cutoffs in the parameters section above, and the settings used are pretty standard in the world of ERP analysis: a high-pass (low frequency) cutoff of 0.1 Hz, and a low-pass (high frequency) cutoff of 30 Hz (some researchers use 40 Hz instead). Together, this is called a **band pass filter**, because we preseve a \"band\" of frequencies between teh high-pass and low-pass cutoffs. \n",
    "\n",
    "These settings strike an optimal balance between attenuating artifacts outside the range of human EEG signals of interest, without inducing artifacts of their own. These artifacts typically occur if the filter cutoffs are too close to the range of frequencies of scientific interest. It turns ou that the high-pass cutoff needs to be much lower (by a factor of about 10) than the lowest frequency of interest (hence 0.1 when our lowest frequency of interest is 1 Hz), while the low-pass cutoff can be much closer to the highest frequency of interest (in most ERP research, components of interest are rarely higher than about 10 Hz).\n",
    "\n",
    "### Always filter first\n",
    "\n",
    "Filtering should always be one of the first preprocessing steps you apply to your data. Most importantly, filtering should be applied to the continuous, raw EEG data before it is chopped into short segments time-locked to the event codes of interest. This is because we need long segments of data in order to accurately estimate and remove low frequencies. For example, our low frequency cutoff of 0.1 Hz corresponds to one sine wave oscillation every 10 sec, and we would need 20-30 s of data to estimate this accurately. A typical segment of data for ERP analysis is only about 1-2 s long at most, and so once your data are segmented, you can't remove low frequencies. Even for high frequencies, filtering results in removing the first and last few data points from the data (for technical reasons we won't cover here), and so again it's better to filter at the start and not worry about it later.\n",
    "\n",
    "MNE provides a `.filter()` method for `Raw` data that is simple to apply, but is actually very powerful because of the many options provided. If you're interested in more detailed discussion of how filtering works, both in general and in MNE, their website has a very detailed [discussion of filtering](https://mne.tools/stable/auto_tutorials/preprocessing/25_background_filtering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd1da7-04d9-4ffd-87c6-e9828f6cb77b",
   "metadata": {},
   "source": [
    "### Plot the frequency spectrum of the raw data\n",
    "\n",
    "MNE's `.plot_psd()` method plots the **power spectral density** (PSD) of a data set. *Power* refers to the amplitude of sine waves when we are working in the frequency domain, *spectrum* means a range of frequencies, and *density* basically means we're quantifying the power over a range of frequencies. In a sense, you can think of a PSD as a histogram of frequency information — frequency is a continuous variable that is divided into bins (bin size is determined automatically), and the amount of power is plotted for each frequency bin. We set the `fmax` kwarg to 100 because we aren't interested in frequencies above this.\n",
    "\n",
    "MNE automatically colour-codes electrodes based on their position on the scalp, as shown in the inset to the figure, and the lines in the PSD represent the data from each corresponding electrode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c81bd-85d4-4197-ba4f-303edb2fe413",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(fmax=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b1681-91cf-4db9-afd3-e45049749b6c",
   "metadata": {},
   "source": [
    "The PSD shows a clear spike at 60 Hz, which is the frequency of AC electrical service in Canada, where the data was recorded. This is the electromagnetic interference mentioned above.\n",
    "\n",
    "The PSD also shows a typical property of human EEG (and many other kinds frequency spectra), known as the **1 / *f*** property. That is, power is highest at the lowest frequencies, and drops off with increasing frequency. The dropoff is not linear (a diagonal line), but rather decreases at approximately 1 divided by the frequency. \n",
    "\n",
    "The vertical dashed line shows the low-pass cutoff that was used during data acquisition. This information was stored in the EEG header file, and read by MNE when the data was imported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20569a-54dc-457a-ae25-5213a60a8fb5",
   "metadata": {},
   "source": [
    "### Filter the raw data\n",
    "\n",
    "We need to chain the `.copy()` and `.filter()` methods because by default, the `.filter()` method modifies the raw data in-place, rather than creating a new, filtered copy of the data. This is sensible for managing the memory used, but can create problems if we want to change the filter settings and redo the filtering step. \n",
    "\n",
    "All of the parameters used for filtering were defined at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa19072-492f-4477-9ed6-dbe10f2fe1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filt = raw.copy().filter(low_cut, hi_cut,\n",
    "                             l_trans_bandwidth = l_trans_bandwidth,\n",
    "                             h_trans_bandwidth = h_trans_bandwidth,\n",
    "                             filter_length=filter_length,\n",
    "                             method=filter_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb695b7e-0c2e-42f1-8f4f-cec17ed67126",
   "metadata": {},
   "source": [
    "### Plot the frequency spectrum of the filtered data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee141a83-dbe8-4f4e-85cc-b1b3f9a63a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filt.plot_psd(fmax=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faba0bb-9363-417d-bb62-595728fbec7e",
   "metadata": {},
   "source": [
    "The effects of our low-pass filter are quite evident — in comparison to the pre-filtering PSD, there is a dramatic drop in power above our 30 Hz cutoff (note that the dashed line has moved to reflect our new low-pass cutoff). The spike at 60 Hz is gone (actually it's still there, but very small), because the filtering virtually eliminated this noise from the data. \n",
    "\n",
    "The effects of the high-pass filtering are much harder to see, since the scale is linear from 0–100 Hz, but our cutoff of 0.1 Hz was very close to zero. If we set `fmax` to 10 we can see the effects of the high-pass cutoff more clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59968501-3971-4928-86d1-7cc7893e6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filt.plot_psd(fmax=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b848d6-8a83-4f33-8734-204c791ab32f",
   "metadata": {},
   "source": [
    "Note that for both the high- and low-pass filters, the power does not drop of sharply right at the cutoff frequency we specified. Rather, there is a **roll-off** — a range of frequencies over which the power gradually decreases. The shape of the roll-off is a property of the filter that is determined by its parameters, and some roll-off is a necessary feature of any filter if aftifacts are to be avoided. Again, this is a deep topic that we won't delve into here, but in general it is useful to remember the adage that *precision in the frequency domain is inversely related to precision in the time domain*. In other words, if we use a sharper frequency cutoff, we are likely to induce larger artifacts in the data, when we view the filtered data in the time domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abdc46-0428-4cbd-b2f8-e6851917e656",
   "metadata": {},
   "source": [
    "### Visualizing the effects of filtering in the time domain\n",
    "\n",
    "Below we plot 5 s of data, comparing the raw and filtered versions.\n",
    "\n",
    "#### Unfiltered\n",
    "\n",
    "Note the high frequency noise in virtually all channels — the oscillations that occur very rapidly. This is particularly large in channel F8. This is primarily 60 Hz line noise. \n",
    "\n",
    "Channels F8 and Fp2 show low frequency noise as well — these are the slow drifts up and down seen in these channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57a4e4-075d-4081-91f1-14ef344446df",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(start=50, duration=5);  # times are in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261ad64-db9d-4c85-b5ac-d6a240123bf7",
   "metadata": {},
   "source": [
    "#### Filtered\n",
    "\n",
    "The plot below shows the same sample of data after filtering. The high frequency noise is gone. The low-frequency noise is perhaps a bit reduced, but not eliminated. This is because our high-pass filter setting was 0.1 Hz, which means that only frequencies below 1 cycle per 10 sec would be reduced. These are so slow that we would not even see much evidence of them in 5 sec of data. Although we could filter the data with a higher high-pass cutoff (e.g., 1 Hz instead of 0.1 Hz), this risks inducing artifacts into the data ([Tanner, Morgan-Short, & Luck, 2015](https://doi.org/10.1111/psyp.12437)), so we don't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b44e4-c80b-4a31-9cf2-d12f1618cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filt.plot(start=50, duration=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e2e4e-7d4e-4eba-8ae5-d7ad38c6e821",
   "metadata": {},
   "source": [
    "## Artifacts in EEG Data\n",
    "\n",
    "Recall that the term **artifact** in EEG refers to any noise in the data that can be attributed to a specific source. So eye blinks, eye movements, and muscle contractions are all types of artifacts. It is important to remove these from the data, to increase our confidence that the results we ultimately interpret are actually due to brain activity, and not these other sources.\n",
    "\n",
    "Common physiological artifacts, including eye blinks, eye movements, and muscle contractions, have highly characteristic properties in time and frequency. Examples of each are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4282a5-9a92-490b-ac55-bf91c11c258e",
   "metadata": {},
   "source": [
    "### Eye blink\n",
    "\n",
    "There are a series of several eye blinks in the data below, the first at 242 s. You can see that the size of eye blink artifacts are typically on the order of 10x as large as ongoing EEG, which is why they are such a problem. \n",
    "\n",
    "<img src='images/eog_blink.png' width=400>\n",
    "\n",
    "Because the artifact originates at the eyes, is is picked up most strongly by the electrodes on the forehead, Fp1 and Fp2, as well as other frontal electrodes (the ones whose labels start with *F*, though much smaller). The electrical potential sharply increases, then decreases, over a period of about 250-300 ms for a typical blink. The artifact actually *inverts* at more posterior electrodes, for example at TP9 and TP10 in the figure above. These are the characteristic properties of an eye blink artifact, which can be used to identify them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f051166-e4f6-46ab-847e-5c3304dff205",
   "metadata": {},
   "source": [
    "### Eye movements\n",
    "\n",
    "The neurons in the retina are organized in a highly oriented fashion, such that they form an electrical **dipole** — a source with positive and negative poles. This is exactly the kind of electrical source that EEG is good at detecting. As long as the eye's position doesn't change, the diploe created by the retina doesn't affect EEG recordings, because it is constant (not changing). However, as the eye moves to look at different locations in space, the dipole moves, and this is detected by the electrodes on the scalp. When they eyes move to the left or right, the effect on EEG electrodes is that the electrical potential will increase at frontal electrodes on one side of the head, and decrease on the other side. Which side becomes more positive or negative depends on the direction of the movement. \n",
    "\n",
    "An example of a horizontal eye movement is shown in the figure below, overlapping the time where the vertical green line is shown (this line is an event marker, but this is irrelevant for our present purposes). At electrodes Fp1 and Fp2, the artifact looks very similar to a blink. However, note how there is a roughly \"square wave\" effect at electrodes F7 and F8 (and to a lesser extent, at F3 and F4), and that this goes positive at F7/F3, and negative at F8/F4. This is the hallmark of a horizontal eye movement artifact. In the example below, the horizontal eye movement is followed by two blinks. We can tell these are blinks because the polarity (direction of change) at both F7 and F8 is the same (positive/upward).\n",
    "\n",
    "<img src='images/eog_horiz.png' width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613ec69-f7ae-485d-b373-0d395c5883ce",
   "metadata": {},
   "source": [
    "### Muscle contractions\n",
    "\n",
    "In the figure below, note the increase in high frequency activity starting just after 872 s, especially at channels F3, F7, and TP9. This is typical of a muscle contraction, likely of the face and/or neck. Brief contractions like this are usually not a problem, but if the participant is tense throughout the experiment, or at least for extended periods, then this high frequency noise can make it more challenging to detect ERPs. Muscle contractions typically have a fairly broad frequency range, from about 20-40 Hz, which means that this artifact will be present even after the data is band-pass filtered.\n",
    "\n",
    "<img src='images/eeg_muscle.png' width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064d951-c925-4b3e-baa8-e0512148d6e3",
   "metadata": {},
   "source": [
    "## Artifact removal with Independent Components Analysis (ICA)\n",
    "\n",
    "ICA is a *blind source separation* algorithm. In other words, it can take a complex signal and separate it into mathematically independent *components*. Note that the term \"components\" here is not used in the sense of ERP components (like the N170 or N400) that were discussed earlier. Rather, in ICA *components* are the individual underlying signals that were mixed together during recording. So for example, in EEG each electrode will record a mixture of brain activity (which itself may comprise multiple sources within the brain, such as the activity of different brain areas) and noise (including physiological and non-physiological artifacts). ICA is capable of separating EEG from artifacts (and separating different types of artifacts) because, over time and across all of hte recording electrodes, each signal with a different source will have different spatio-temporal properties. \n",
    "\n",
    "A nice example of using ICA, that may seem a. bit less abstract than EEG data, is audio recording. Imagine that we have two people in a room having a conversation, and there is background noise in the room such as from the ventilation system. If we have a single microphone in the room, all three signals (person A, person B, and the ventilation) will be mixed in the recording and it will be hard to separate them. However, if we have three microphones at different locations in the room, then each will pick up all three sound sources, but to different degrees depending on the location of each microphone. ICA can use the audio from all three microphones to find independent sources in the data (i.e., person A, person B, and the ventilation), based on how the sounds from each person, and the ventilation, differ systematically across the three microphones. But this only works because we have multiple independent sources (the microphones) sampling the data from different locations.\n",
    "\n",
    "Likewise with EEG, it is necessary to have multiple electrodes (the sources) to run ICA. The maximum number of ICA components  that can be derived from a data set is equal to the number of electrodes (channels) we have. However, in practice the number of independent sources in the data is lower than the number of electrodes, and we can limit the number of ICA components accordingly, as we'll see below. \n",
    "\n",
    "In EEG, ICA has become widely used for artifact identification and removal. This is because it does a very good job of identifying ocular artifacts (blinks and eye movements), and also usually muscle artifact as well. Moreover, because the different ICA components are mathematically independent of each other, having identified which components are \"noise\" (such as blinks), we can remove these components from the data without affecting the other components. This means we can effectively remove the effects of ocular artifacts from the data, while preserving the EEG signals. This is usually preferable to older approaches, such as removing any trial containing an artifact from the data set completely. ICA allows us to remove artifacts while keeping all of the trials. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c3b54-46c8-4a54-bb97-ea84bc187405",
   "metadata": {},
   "source": [
    "### Filter data for ICA\n",
    "\n",
    "ICA is very good at capturing features of the data that explain the most *variance*. Recall that variance, statistically speaking, is any deviation from the mean. Blinks and eye movements are well-captured by ICA because they are so much larger than EEG, and so they contain a lot of the variance in the EEG recordings. Likewise, low-frequency drift in the data explains large amounts of variance, because of the 1/f property of EEG data discussed earlier — the lowest frequencies contain the most power. For this reason, ICA works best on data that has more low-frequency power removed than the data that we ultimately want to analyze. So we will filter the data for ICA with a 1 Hz high-pass cutoff, rather than a 0.1 Hz cutoff as we used above. A useful property of ICA is that we can compute ICA based on a more-filtered version of the data, identify the artifacts based on this, and then apply the same ICA decomposition (i.e., how ICA breaks the data down into components) to the data that were filtered as we wanted for ERP analysis. Below we do this, running the same filtering command as we did earlier, except with a different high-pass (low frequency) cut-off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb315b-dea2-4306-a20d-63919e219fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_low_cut = 1.0       # For ICA, we filter out more low-frequency power\n",
    "\n",
    "raw_ica = raw.copy().filter(ica_low_cut, hi_cut,\n",
    "                             l_trans_bandwidth = l_trans_bandwidth,\n",
    "                             h_trans_bandwidth = h_trans_bandwidth,\n",
    "                             filter_length=filter_length,\n",
    "                             method=filter_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e54e1b-0704-4d39-b232-77b092ac5387",
   "metadata": {},
   "source": [
    "### Clean data for ICA\n",
    "\n",
    "Besides filtering out low-frequency noise, we want to identify any sections of EEG data that have excessive noise. This can occur, for example, if a participant scratches their head during a recording, or sneezes, or for various other reasons. These \"one-off\" sources of noise can create large artifacts in the data. Since large amplitudes mean high variance, the presence of these artifacts can interfere with ICA's finding more frequent artifacts like blinks — since blinks are larger than EEG data, but smaller than these one-off sources of noise. Another possible source of noise in EEG data is bad channels — electrodes taht for some reason produced poor-quality data. Sometimes, and electrode is broken, or for some reason doesn't have a good connection to the scalp, and in that case the data from it may contain no EEG signal whatsoever, or at least excessive noise. For bad channels, the best approach is to identify them and mark them as \"bad\" in the data set (MNE's data objects have an attribute `bads` to keep track of these). Channels marked as \"bad\" will be ignored by MNE functions and, after preprocessing of good channels, the data from bad channels can be interpolated from the other (good) electrodes around it. \n",
    "\n",
    "It is possible to go through the data manually to identify and remove these large artifacts and bad channels, but fortunately there is a companion package to MNE, called `autoreject`, that will do this for us. We'll import the functions we need from this package here, along with a couple of other functions we'll need. Normally it's good practice to import all the packages you'll need at the top of a notebook, but we're doing it here for the purposes of explaining which packages are being used for what purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f19174-792a-4ffc-9c9c-80d74d5d1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoreject import Ransac, get_rejection_threshold, AutoReject\n",
    "from mne.viz.ica import _prepare_data_ica_properties\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790fd423-bf83-4b0a-baa0-2cd1725bd4f8",
   "metadata": {},
   "source": [
    "ICA likes to work with segments of data, rather than the continuous raw data. We call segments of EEG data **epochs**, a word which means \"a period of time\". Typically when talking about ERPs, *epochs* refers to the segments of data that are time-locked to experimental events of interest. Here, however, we use the term more generically to refer to any segment of EEG data. So here we will segment the entire raw data recording into a series of 1 s segments, and save these as `epochs_ica`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f540d93-ba21-4cb0-939c-db0746d2af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break raw data into 1 s epochs\n",
    "tstep = 1.0\n",
    "events_ica = mne.make_fixed_length_events(raw_ica, duration=tstep)\n",
    "epochs_ica = mne.Epochs(raw_ica, events_ica,\n",
    "                        tmin=0.0, tmax=tstep,\n",
    "                        baseline=None,\n",
    "                        preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce6c4b-d449-4920-b6e6-a9deab3df563",
   "metadata": {},
   "source": [
    "Next we run an MNE function that will look at the data and automatically determine a threshold to use to find sections of the data that are \"excessively\" noisy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca69bc7-1039-4916-820d-cdb40c810c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find appropriate rejection threshold to eliminate noisy trials from ICA fitting\n",
    "reject = get_rejection_threshold(epochs_ica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b1076-22a9-4078-9d2c-2ef722dcdb78",
   "metadata": {},
   "source": [
    "Then we run a function from `autoreject` called `Ransac` that will automatically identify and remove any excessive noise and/or bad channels. Running this involves two steps: \n",
    "1. Create a `Ransac` *object* with the parameters (kwargs) that we want to use\n",
    "1. `fit` this object to the data — which effectively runs the algorithm on the data, using the parameters set in step 1\n",
    "\n",
    "This may seem overly complex — why define and object and then apply a `.fit()` method, rather than having a method that we just apply to the data in a single step/line of code?  \n",
    "\n",
    "The reason relates to the nature of object-oriented languages. By creating a `Ransac` object, we have a data structure — separate from the EEG data itself — that stores important information about this preprocessing step. Afgter we fit the `ransac` object to the data, the object contains the values that were estimated from the data. In other words, running `.fit()` on the data *doesn't change the data itself*, only the `Ransac` object. That way, this step is \"non-destructive\" in the sense that if we aren't happy with the results, we don't need to worry about re-loading our data — we can simply modify parameters of the `Ransac` object and re-fit it. We'll do this for ICA as well and, as we'll learn later in the course, this is actually the primary way in which machine learning and statistical models are fit to data sets in Python. \n",
    "\n",
    "Note that this is computationally expensive and will take a little while to run (anywhere from 10 s to several minutes, depending on your computer system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef52e6c-55dc-410b-8f9b-4012f5fc032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ransac object with desired parameters\n",
    "ransac = Ransac(random_state=ica_random_state, verbose=False)\n",
    "# Fit Ransac object to data\n",
    "ransac.fit(epochs_ica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b04b02-8666-4ca2-b6d2-8ca2364bc89d",
   "metadata": {},
   "source": [
    "Critically, at this step the only information we want from Ransac is which channels should be marked as \"bad\", if any. This is stored in an attribute of the object named `.bad_chs_`, which we will now copy to the `bads` attribute of the data set we're going to apply ICA to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e496647-7787-484c-9348-a4b7b903e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.info['bads'] = ransac.bad_chs_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ed38c-1149-4183-8e90-b786122002e3",
   "metadata": {},
   "source": [
    "### Fit ICA to data\n",
    "\n",
    "Next we create an `ICA` object, as we did before for Ransac, setting the parameters we desire, and then fit it.\n",
    "\n",
    "The first parameter that we want to specify is the number of independent components we want. Recall that by default, ICA will compute as many components as there are channels in the data, but this is typically more than is necessary or useful. The `n_components` parameter of ICA can be specified in one of two ways. One is to provide an integer specifying the actual number of components desired. An optimal number for this, however, is hard to know in advance. The other way is to specify a floating point number ≤ 1, which represents the percentage of data that the ICA components should, collectively, explain. Here we use `.99`, which means we want as many independent components as needed to explain 99% of the variance in the data. Typically this is a good value to use.\n",
    "\n",
    "The other parameter is `random_state`. We use this because ICA is an *iterative* algorithm that starts with a set of random parameters, and then over a series of fitting steps computes the optimal values of these parameters. The set of random parameters it starts with determines the results to some extent. That is, if you fit ICA repeatedly to the data, you will generally get very similar, but not identical, results each time, because of the different random starting points. By specifying a `random_state`, we ensure that the same \"random\" parameters are used each time, meaning that our results will be replicable. The value 42 is used by convention, because it is the \"Answer to the Ultimate Question of Life, the Universe, and Everything\" in *The Hitchhiker's Guide to the Galaxy* (Adams, 1979).\n",
    "\n",
    "In fitting ICA to the data, we include a couple of other parameters, which were defined earlier. `reject` comes from `get_rejection_threshold`, and `tstep` is the 1 s intervals that we segmented our data in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8adac-c05d-4afa-a700-bc71a883bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA parameters\n",
    "ica_random_state = 42   # ensures ICA is reproducable each time it's run\n",
    "ica_n_components = .99     # Specify n_components as a decimal to set % explained variance\n",
    "\n",
    "# Fit ICA\n",
    "ica = mne.preprocessing.ICA(n_components=ica_n_components,\n",
    "                            random_state=ica_random_state,\n",
    "                            )\n",
    "ica.fit(epochs_ica,\n",
    "        reject=reject,\n",
    "        tstep=tstep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2bc068-085e-490e-9e00-2b37aaee5cb2",
   "metadata": {},
   "source": [
    "The `.fit()` step produces the output you see above, showing some of the resulting parameters stored in `ica`.\n",
    "\n",
    "### Visualize ICA components\n",
    "\n",
    "We can visualize each component as a scalp map, showing where it \"weights\" most heavily on the scalp. By \"weights\" we mean, which electrodes the component is largest at. The maps use the red-blue colour map where red is positive, blue is negative, and white is zero. \n",
    "\n",
    "In the figure below, we can see that a few components are likely ocular artifacts, because they weight most heavily around the front of the head (the top of each subplot, where the nose is drawn). In particular, ICA003 is likely blink artifact, and ICA004 is likely horizontal eye movement. ICA007 may be eye movement as well, however it does not show opposite polarity on either side of the head as we would expect from a horizontal (sideways) eye movement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0c5d6-6577-44f5-a8a3-126113a26ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb7e0d-373a-4f8a-80fa-a937a0bb57ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c0497-620a-463b-9957-017a42b25a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_properties(epochs_ica, picks=range(0,ica.n_components_), psd_args={'fmax': hi_cut});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77602168-8516-4dfd-b65a-65240299d8a5",
   "metadata": {},
   "source": [
    "### Identify EOG artifacts from ICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efd8e0-3c65-465a-a4df-d380a2a80800",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_z_thresh = 2.3 \n",
    "raw_ica.set_channel_types({'Fp1':'eog', 'Fp2':'eog', 'F7':'eog', 'F8':'eog'})\n",
    "eog_indices, eog_scores = ica.find_bads_eog(raw_ica, threshold=ica_z_thresh)\n",
    "ica.exclude = eog_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9702662-6bcc-446a-a16f-9526156c9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_scores(eog_scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133780-fd45-49df-a960-2b5b4a76cce9",
   "metadata": {},
   "source": [
    "#### Segment filtered raw data into epochs for final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b66bb7-bed7-4f7a-ace5-6d8fd9467e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw_filt,\n",
    "                    events_new, event_id_new,\n",
    "                    tmin, tmax,\n",
    "                    baseline=baseline, detrend=detrend,\n",
    "                    reject=reject, flat=None,\n",
    "                    preload=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328576a-a351-4b0d-a7e1-84fd72095b2b",
   "metadata": {},
   "source": [
    "### Apply ICA correction to epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b83d11-2d77-4742-b744-a4907e7a07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_postica = ica.apply(epochs.copy())\n",
    "epochs_postica.info['bads'] = ransac.bad_chs_\n",
    "epochs_postica = epochs_postica.interpolate_bads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c8088-2004-47ac-8f79-dcff598416c9",
   "metadata": {},
   "source": [
    "### Apply AutoReject to clean epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d41cd4-cadb-43f0-a23d-31e7751f4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = AutoReject(n_jobs=n_jobs, random_state=ica_random_state, verbose=False)\n",
    "epochs_clean = ar.fit_transform(epochs_postica)\n",
    "# Re-reference to average of all channels, now that they are cleaned\n",
    "epochs_clean.set_eeg_reference(ref_channels='average');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6390dd-e2d9-442d-94a3-75f3f36144d6",
   "metadata": {},
   "source": [
    "### Report on how much was rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87e163-9a6d-4d32-bcd4-947d47ba95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_epochs = epochs_postica.selection.shape[0] - epochs_clean.selection.shape[0]\n",
    "pct_epochs = rm_epochs / epochs_postica.selection.shape[0] * 100\n",
    "print('n epochs removed: ' + str(rm_epochs)\n",
    "      + '\\nrepresenting ' + str(round(pct_epochs, 2)) + ' % of data')\n",
    "\n",
    "# Save log of rejections\n",
    "rej_log_list.append(pd.DataFrame({'Subject':subject,\n",
    "                                  'n Trials Rej':rm_epochs,\n",
    "                                  '% Trials Rej':round(pct_epochs, 2),\n",
    "                                  'n Chans Fixed':len(epochs_ica.info['bads']),\n",
    "                                  'n ICs removed':len(ica.exclude)\n",
    "                                  }, index=[0])\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374388b0-e9f9-4f5a-8201-a2d19ef20f17",
   "metadata": {},
   "source": [
    "### Save cleaned epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fae728-8da1-40ff-9d79-c610ca85c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean.save(epochs_fname, overwrite=True)\n",
    "\n",
    "fig = epochs_clean.average().plot(spatial_colors=True, show=False);\n",
    "plt.show()\n",
    "\n",
    "rej_log = pd.concat(rej_log_list, ignore_index=True)\n",
    "rej_log.to_csv(log_path + p_id + '_rej_log.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
